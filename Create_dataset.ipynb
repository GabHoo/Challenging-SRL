{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook containes all the functions and manually created sentences to further generate (Automatically or semi-automatically) the test sets used in *Challenging-SRL*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "from checklist.editor import Editor\n",
    "from checklist.perturb import Perturb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicate identification test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All the sentences generated will be stred in this folder:\n",
    "path=\"./Data/Predicate_identification/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data for contraction VERB identification.\n",
    "\n",
    "Creation semi manual of the contraction data test.  \n",
    "Some initial predicates that can be subjected to this phenomena are written by the author and Checklist will contract or expand the sentence.  \n",
    "The list is not exhaustive and can be always be expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contractions(data):\n",
    "    \"\"\"This function creates contractions from a list of sentences.\n",
    "    :data is a list of sentences\n",
    "    Returns a Dict in the shape {'contracted_couples':[[s1,s2]]}\n",
    "    \"\"\"\n",
    "    ret = Perturb.perturb(data, Perturb.contractions)\n",
    "    return {\"contracted_couples\":ret.data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['it\\'s a wonderfull day',\n",
    "        \"There's some pesto left\",\n",
    "        \"I shoud have tried that as well\",#!\n",
    "        \"They will leave the house\",\n",
    "        \"That would be creazy\",\n",
    "        \"we are here\",\n",
    "        'Mark had not see that coming',\n",
    "        'She will be a great candidate',\n",
    "        'Mary is not a nurse.',\n",
    "        'He\\'s gone already',\n",
    "        \"I would like some tea\",\n",
    "        \"I would say something to them\",\n",
    "        \"I could not eat some food now\",\n",
    "        'We\\'ve decided to change house',\n",
    "        \"I must not lose my temper\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " {'contracted_couples': [[\"it's a wonderfull day\", 'it is a wonderfull day'],\n",
       "   [\"There's some pesto left\", 'There is some pesto left'],\n",
       "   ['They will leave the house', \"They'll leave the house\"],\n",
       "   ['That would be creazy', \"That'd be creazy\"],\n",
       "   ['we are here', \"we're here\"],\n",
       "   ['Mark had not see that coming', \"Mark hadn't see that coming\"],\n",
       "   ['She will be a great candidate', \"She'll be a great candidate\"],\n",
       "   ['Mary is not a nurse.', \"Mary isn't a nurse.\"],\n",
       "   [\"He's gone already\", 'He is gone already'],\n",
       "   ['I would like some tea', \"I'd like some tea\"],\n",
       "   ['I would say something to them', \"I'd say something to them\"],\n",
       "   ['I could not eat some food now', \"I couldn't eat some food now\"],\n",
       "   [\"We've decided to change house\", 'We have decided to change house'],\n",
       "   ['I must not lose my temper', \"I mustn't lose my temper\"]]})"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contracted_sentences=create_contractions(data)\n",
    "len(contracted_sentences),contracted_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+\"contracted_sentences.json\",\"w\") as f:\n",
    "    json.dump(contracted_sentences,f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicate irregular inflections\n",
    "Semi automatic creation of sentences using a list of irregular inflected verb.  \n",
    "List was found online / written by the authros. Example sentences are contructed with Large Language Model RoBerta integrated in CheckList library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inflected_sentences(irregular_inflections):\n",
    "    \"\"\"This function creates a dictionary in the shape {label:sentence}. Where label is the inflected verb form.\n",
    "    :irregular_inflections is a list of the irregular verbs to be used.\n",
    "    returns Dict\n",
    "    \"\"\"\n",
    "    editor = Editor()\n",
    "    #This will add the irregular verbs to the lexicon so that we can use them in the template.\n",
    "    editor.add_lexicon('irr_verb', irregular_inflections,remove_duplicates=True)\n",
    "\n",
    "    #This will create 1000 samples sentences and their lables will be the irregular verb picked.\n",
    "    #{mask} is a special token that will be replaced by a random word suggested by the Language model.\n",
    "    #{fist_name} is a special token that will be replaced by a random first name in the lexicon.\n",
    "    ret = editor.template('{first_name} {irr_verb} {a:mask} {mask}.',nsamples=100,labels='{irr_verb}')\n",
    "\n",
    "    #This creates a dictionary in the shape {label:sentence}. Where label is the verb.\n",
    "    #Carefull, this will be much smaller than the number of samples because some of the sentences will be duplicates.\n",
    "    inflected_sentences=dict(zip(ret.labels,ret.data))\n",
    "\n",
    "\n",
    "    return inflected_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "irregular_inflections=['Beheld', 'Dwelt', 'Flung', 'Broadcast', 'Clung', 'Dared', 'Fitted', 'Forgave', 'Grinded', 'Hanged', 'Knelt', 'Laid', 'Led', 'Leant', 'Molten', 'Mistook', 'Proved', 'Rose', 'Sawn', 'Sought', 'Sewed', 'Shaven', 'Slit', 'Snuck', 'Span', 'Spoiled', 'Spring', 'Stuck', 'Strode', 'Struck', 'Swung', 'Torn', 'Undertook', 'Vext', 'Wet', 'Wrote']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35,\n",
       " {'Leant': 'Christopher Leant a H __.',\n",
       "  'Knelt': 'Elizabeth Knelt an Old Woman.',\n",
       "  'Snuck': 'Katherine Snuck an Old Swan.',\n",
       "  'Rose': 'Al Rose a L Key.',\n",
       "  'Forgave': 'Al Forgave a New Thing.',\n",
       "  'Span': 'Joan Span a New Order.',\n",
       "  'Strode': 'Lauren Strode a L Stand.',\n",
       "  'Sewed': 'Christopher Sewed a L 3.',\n",
       "  'Undertook': 'Steve Undertook an Old Rose.',\n",
       "  'Led': 'Peter Led a H in.',\n",
       "  'Dwelt': 'Frances Dwelt a L No.',\n",
       "  'Swung': 'Paul Swung a H Band.',\n",
       "  'Sawn': 'Fiona Sawn an Old Girl.',\n",
       "  'Vext': 'Gary Vext an A Rose.',\n",
       "  'Flung': 'Frederick Flung a H Bar.',\n",
       "  'Wet': 'Donald Wet a R Road.',\n",
       "  'Slit': 'Catherine Slit a H Ranch.',\n",
       "  'Fitted': 'Henry Fitted a L 0.',\n",
       "  'Mistook': 'Emily Mistook an In A.',\n",
       "  'Dared': 'Jennifer Dared an Old Friend.',\n",
       "  'Spoiled': 'Al Spoiled a L Stand.',\n",
       "  'Shaven': 'Sue Shaven a H in.',\n",
       "  'Sought': 'Martha Sought a L Ring.',\n",
       "  'Molten': 'Bill Molten an Old Thing.',\n",
       "  'Hanged': 'Susan Hanged an Old Car.',\n",
       "  'Stuck': 'Frank Stuck a R Post.',\n",
       "  'Proved': 'Simon Proved a L H.',\n",
       "  'Broadcast': 'Mark Broadcast a L Stand.',\n",
       "  'Beheld': 'Sarah Beheld an Old Rose.',\n",
       "  'Struck': 'Kathy Struck a New Frontier.',\n",
       "  'Laid': 'Christine Laid a L K.',\n",
       "  'Wrote': 'Frances Wrote an Old Chair.',\n",
       "  'Torn': 'Michelle Torn a New Order.',\n",
       "  'Grinded': 'Jay Grinded an A Lot.',\n",
       "  'Spring': 'Sarah Spring a L 3.'})"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inflected_sentences=create_inflected_sentences(irregular_inflections)\n",
    "len(inflected_sentences),inflected_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+\"inflected_sentences.json\",\"w\") as f:\n",
    "    json.dump(inflected_sentences,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlptasks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
