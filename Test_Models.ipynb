{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GabHoo/Challenging-SRL/blob/main/Test_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SETTING UP\n",
        "Run the following cells in the Settin Up section to be able to run any of the tests in this notebook with the two suggested models.  \n",
        "Change the current value for both model path according to your own models location. If No models are found they will be downloaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "iDMzdKns-m8m"
      },
      "outputs": [],
      "source": [
        "# INSTALL AND IMPORTS\n",
        "\"\"\"\n",
        "pip install allennlp\n",
        "pip install allennlp-models\n",
        "pip install -U spaCy\n",
        "pip install checklist\n",
        "\"\"\"\n",
        "from allennlp.predictors import Predictor\n",
        "import allennlp_models.tagging\n",
        "\n",
        "import json\n",
        "import os\n",
        "from utils import *\n",
        "import utils\n",
        "import re\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Change the model here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model found!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/gabhoo/.local/lib/python3.10/site-packages/spacy/util.py:887: UserWarning: [W095] Model 'en_core_web_sm' (3.3.0) was trained with spaCy v3.3 and may not be 100% compatible with the current version (3.5.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SRL model was loaded succeffully !\n"
          ]
        }
      ],
      "source": [
        "#LOADING MODEL\n",
        "model=\"Bilstm\"\n",
        "\n",
        "if model==\"Bert\":\n",
        "    model_name=\"structured-prediction-srl-bert.2020.12.15.tar.gz\"\n",
        "    path_model=\"models/\"+model_name\n",
        "elif model==\"Bilstm\":\n",
        "    model_name=\"openie-model.2020.03.26.tar.gz\"\n",
        "    path_model=\"models/\"+model_name\n",
        "else:\n",
        "    print(\"Model not found!\")\n",
        "    exit()\n",
        "\n",
        "if os.path.exists(path_model):\n",
        "    print(\"Model found!\")\n",
        "    predictor = Predictor.from_path(path_model)\n",
        "else:\n",
        "    predictor = Predictor.from_path(\"https://storage.googleapis.com/\"+model_name)\n",
        "\n",
        "#TESTING IF THE MODELS ARE LOADED CORRECTLY\n",
        "\n",
        "pred=predictor.predict(\"SRL model was loaded succeffully!\")\n",
        "if pred :\n",
        "    print((\" \").join(pred['words'])) \n",
        "    "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bqIKaBdxF1NF"
      },
      "source": [
        "# Useful functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def append_to_results(results_path,your_result):\n",
        "    \"\"\"Add results to the score board. \n",
        "    your_Results neets to be a dictionary alraedy'\n",
        "    \"\"\"\n",
        "    if type(your_result) != dict:\n",
        "        print(\"your_result needs to be a dictionary!\")\n",
        "        return\n",
        "    \n",
        "    with open(results_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    data.update(your_result)\n",
        "\n",
        "    with open(results_path, 'w') as f:\n",
        "        json.dump(data, f,indent=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pWslkmPkPFcy"
      },
      "source": [
        "# PREDICATE IDENTIFICATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "#In this folder we have the data for the predicate classidication task. Change the path accordingly if files were moved.\n",
        "path=\"./Data/Predicate_identification/\"\n",
        "results_path=f\"./results_{model}_Predicate_Identification.json\"\n",
        "## we initialize also the dictionary that will contain the results\n",
        "with open(results_path, 'w') as f:\n",
        "    json.dump({\"test\":\"failure_rate\"},f)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PkrGLpJMKSwn"
      },
      "source": [
        "## VOCABULARY+POS"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cCOznqQ_N9-z"
      },
      "source": [
        "### Test for contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failure in I'd like some tea | I would like some tea\n",
            "The alteration of verb 'd/would lead to a different labeling:\n",
            "\n",
            "{'verb': \"'d\", 'description': \"I 'd like some tea\", 'tags': ['O', 'O', 'O', 'O', 'O']}\n",
            "{'verb': 'would', 'description': '[ARG0: I] [V: would] [ARG1: like] [ARG1: some tea]', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'B-ARG1', 'I-ARG1']}\n",
            "Failure rate: 5.555555555555555. Total number of tests: 18\n"
          ]
        }
      ],
      "source": [
        "data=json.load(open(path+'contracted_sentences.json'))\n",
        "failure_rate=evaluate_PI_Contractions_INV(predictor,data)\n",
        "print(f\"Failure rate: {failure_rate}. Total number of tests: {len(data)}\")\n",
        "append_to_results(results_path,{\"contracted_sentences\":failure_rate})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ldzmhpP_ODor"
      },
      "source": [
        "### Test for irregular inflections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failed for: Gary vext an arm sleeve. did not detect vext\n",
            "\n",
            "Failure rate: 2.857142857142857. Total number of tests: 35\n"
          ]
        }
      ],
      "source": [
        "data=json.load(open(path+\"inflected_sentences.json\"))\n",
        "failure_rate=evaluate_PI_inflections_MFT(predictor,data)\n",
        "print(f\"Failure rate: {failure_rate}. Total number of tests: {len(data)}\")\n",
        "append_to_results(results_path,{\"inflected_sentences\":failure_rate})\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ROBUTSTNESS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failed for: They aet a cool lot. did not detect aet\n",
            "\n",
            "Failure rate: 1.8867924528301887. Total number of tests: 53\n"
          ]
        }
      ],
      "source": [
        "data=json.load(open(path+\"verb_typos_sentence.json\"))\n",
        "failure_rate=evaluate_PI_inflections_MFT(predictor,data)\n",
        "print(f\"Failure rate: {failure_rate}. Total number of tests: {len(data)}\")\n",
        "append_to_results(results_path,{\"inflected_sentences\":failure_rate})\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GIkns01FKdQd"
      },
      "source": [
        "## AMBIGUITY"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "McQzhKS4LCVk"
      },
      "source": [
        "### Experiment with polysemic verbs [POLISEMIC]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37j2bwA3ipm6",
        "outputId": "f14e3a19-db36-42df-c068-3f451f7bd648"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failed for: [I always turn left at the stop sign.],[She left her phone at home.]. left in both did NOT chage the predicate identification\n",
            "['turn', 'left'] ['left']\n",
            "\n",
            "\n",
            "Failed for: [I was lost],[I lost my phone]. lost in both did NOT chage the predicate identification\n",
            "['was', 'lost'] ['lost']\n",
            "\n",
            "\n",
            "Failure rate: 6.896551724137931. Total number of tests: 29\n"
          ]
        }
      ],
      "source": [
        "data=json.load(open(path+'polysem_verbs_sentences.json'))\n",
        "failure_rate=evaluate_PI_Polysem_DIR(predictor,data)\n",
        "print(f\"Failure rate: {failure_rate}. Total number of tests: {len(data)}\")\n",
        "append_to_results(results_path,{\"polysemic_verbs\":failure_rate})\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dY-h4bawK2Ky"
      },
      "source": [
        "### Experiment with verbs being in different roles -ing [GERUNDS]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "paitings not detected from From paintings of his done during that early period, only ['done'] were found ['done']\n",
            "writing not detected from The writing of the thesis took a whole year., only ['took'] were found ['took']\n",
            "singning not detected from The singing of the birds was a welcome sound in the morning., only ['was'] were found ['was']\n",
            "reading not detected from What is your reading on the situation?, only ['is'] were found ['is']\n",
            "cleaning not detected from The cleaning of the house was a tedious chore., only ['was'] were found ['was']\n",
            "washing not detected from The washing of the dishes was a never-ending job., only ['was', 'ending'] were found ['was', 'ending']\n",
            "cooking not detected from I have always enjoyed cooking, it is one of my favourite hobbies., only ['have', 'enjoyed', 'is'] were found ['have', 'enjoyed', 'is']\n",
            "building not detected from The building of the bridge was a remarkable feat of engineering., only ['was'] were found ['was']\n",
            "cutting not detected from The cutting of the cake was the highlight of the party., only ['was'] were found ['was']\n",
            "killing not detected from The protests that followed the killing of the priest were widespread., only ['followed', 'were'] were found ['followed', 'were']\n",
            "interesting not detected from The movie was interesting to watch, only ['was', 'watch'] were found ['was', 'watch']\n",
            "Failure rate: 73.33333333333333. Total number of tests: 15\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'append_to_results' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[49], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m failure_rate\u001b[39m=\u001b[39mfind_roleset_MFT(data,predictor)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailure rate: \u001b[39m\u001b[39m{\u001b[39;00mfailure_rate\u001b[39m}\u001b[39;00m\u001b[39m. Total number of tests: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m append_to_results(results_path,{\u001b[39m\"\u001b[39m\u001b[39mgerunds\u001b[39m\u001b[39m\"\u001b[39m:failure_rate})\n",
            "\u001b[0;31mNameError\u001b[0m: name 'append_to_results' is not defined"
          ]
        }
      ],
      "source": [
        "data=json.load(open(path+\"gerunds.json\"))\n",
        "failure_rate=find_roleset_MFT(data,predictor)\n",
        "print(f\"Failure rate: {failure_rate}. Total number of tests: {len(data)}\")\n",
        "append_to_results(results_path,{\"gerunds\":failure_rate})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn7T5Q02qQNq",
        "outputId": "5fd2da92-1f5f-462f-df8f-234044f88e72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From paintings of his done during that early period\n",
            "['done']\n",
            "The writing on the wall was a warning of what was to come.\n",
            "['was', 'was', 'come']\n",
            "The singing of the birds was a welcome sound in the morning.\n",
            "['was']\n",
            "Singing in the shower is not allowed.\n",
            "['Singing', 'is', 'allowed']\n",
            "What is your reading on the situation?\n",
            "['is']\n",
            "The barking of the dog alerted us to the intruder.\n",
            "['alerted']\n",
            "The cleaning of the house was a tedious chore.\n",
            "['was']\n",
            "The washing of the dishes was a never-ending job.\n",
            "['was', 'ending']\n",
            "The cooking of the meal took longer than expected.\n",
            "['took', 'expected']\n",
            "The building of the bridge was a remarkable feat of engineering.\n",
            "['was']\n",
            "The cutting of the cake was the highlight of the party.\n",
            "['was']\n",
            "I have always enjoyed cooking, it is one of my favourite hobbies.\n",
            "['have', 'enjoyed', 'is']\n",
            "The protests that followed the killing of the priest were widespread.\n",
            "['followed', 'were']\n",
            "The sound of the river running was soothing to listen to.\n",
            "['running', 'was', 'soothing', 'listen']\n",
            "The movie was interesting to watch\n",
            "['was', 'watch']\n",
            "The intruder was alerted by the barking of the dog.\n",
            "['was', 'alerted']\n",
            "The peaceful way to clear my mind was through driving the car.\n",
            "['clear', 'was', 'driving']\n"
          ]
        }
      ],
      "source": [
        "for s in sentences:\n",
        "  print(s)\n",
        "  pred=predictor.predict(s)\n",
        "  \n",
        "  verbs=[x['verb'] for x in pred['verbs']]\n",
        "  #print(pred)\n",
        "  print(verbs)\n",
        "  #print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__TL3O2o_eDZ",
        "outputId": "6da14f21-aea9-44a2-e1b2-099d86d751cd"
      },
      "outputs": [],
      "source": [
        "for s in sentences:\n",
        "  print(s)\n",
        "  pred=predictor.predict(s)\n",
        "  verbs=[x['verb'] for x in pred['verbs']]\n",
        "  print(verbs)\n",
        "  #print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1P59aW9_jtF"
      },
      "outputs": [],
      "source": [
        "prediction=predictor.predict(\n",
        "    sentence=\"I was writing a thesis\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9t_2qBEBjVc",
        "outputId": "d55eb137-9e40-4a51-8e6f-d7985ff0deca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'verbs': [{'verb': 'was',\n",
              "   'description': 'I [V: was] writing a thesis',\n",
              "   'tags': ['O', 'B-V', 'O', 'O', 'O']},\n",
              "  {'verb': 'writing',\n",
              "   'description': '[ARG0: I] was [V: writing] [ARG1: a thesis]',\n",
              "   'tags': ['B-ARG0', 'O', 'B-V', 'B-ARG1', 'I-ARG1']}],\n",
              " 'words': ['I', 'was', 'writing', 'a', 'thesis']}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mte_5-HjBkSU"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import propbank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XsP-z8pWNWD",
        "outputId": "07a9e0a0-7e67-4f74-b45d-40c97b789410"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package propbank to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZL5X6HihG2C",
        "outputId": "ec1e5c3d-4d5c-4225-857d-d7044e574c32"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('treebank')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r21Er3JfWvY1",
        "outputId": "f44a317c-1fc3-4a33-9850-6c76d0d78c5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The birds singing in the morning was a welcome sound.\n",
            "BERT\n",
            "['[ARG0: The birds] [V: singing] [ARGM-TMP: in the morning] was a welcome sound .', '[ARG1: The birds singing in the morning] [V: was] [ARG2: a welcome sound] .']\n",
            "Lstm\n",
            "['[ARG0: The birds] [V: singing] [ARGM-TMP: in the morning] was a welcome sound .', '[ARG1: The birds singing in the morning] [V: was] [ARG2: a welcome sound] .']\n",
            "\n",
            "\n",
            "\n",
            "The singing of birds in the morning was a welcome sound.\n",
            "BERT\n",
            "['[ARG1: The singing of birds in the morning] [V: was] [ARG2: a welcome sound] .']\n",
            "Lstm\n",
            "['[ARG1: The singing of birds in the morning] [V: was] [ARG2: a welcome sound] .']\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sentences=[\"The birds singing in the morning was a welcome sound.\",\"The singing of birds in the morning was a welcome sound.\"]\n",
        "for s in sentences:\n",
        "  print(s)\n",
        "  predBert=predictor.predict(s)\n",
        "  predBilstm=predictor_bilstm.predict(s)\n",
        "  print(\"BERT\")\n",
        "  print([x['description'] for x in predBert['verbs']])\n",
        "\n",
        "  print(\"Lstm\")\n",
        "  print([x['description'] for x in predBilstm['verbs']])\n",
        "  \n",
        "  print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cK0PeYlXtO7",
        "outputId": "30ac96c7-dc93-4c91-f57b-2582d264e887"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It's running low \n",
            "BERT\n",
            "[\"It [V: 's] running low\", \"[ARG0: It] 's [V: running] [ARGM-MNR: low]\"]\n",
            "Lstm\n",
            "[\"It [V: 's] running low\", \"[ARG1: It] 's [V: running] [ARG2: low]\"]\n",
            "\n",
            "\n",
            "\n",
            "It is running low\n",
            "BERT\n",
            "['It [V: is] running low', '[ARG1: It] is [V: running] [ARGM-MNR: low]']\n",
            "Lstm\n",
            "['[ARG1: It] [V: is] [ARG2: running low]', '[ARG1: It] is [V: running] [ARG2: low]']\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sentences=[\"It's running low \",\"It is running low\"]\n",
        "for s in sentences:\n",
        "  print(s)\n",
        "  predBert=predictor.predict(s)\n",
        "  predBilstm=predictor_bilstm.predict(s)\n",
        "  print(\"BERT\")\n",
        "  print([x['description'] for x in predBert['verbs']])\n",
        "\n",
        "  print(\"Lstm\")\n",
        "  print([x['description'] for x in predBilstm['verbs']])\n",
        "  \n",
        "  print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbhrP0sbBsVV"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Su6lKFxWKnbO"
      },
      "source": [
        "## RARITY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data=json.load(open(path+\"verbs_slang.json\"))\n",
        "failure_rate=evaluate_PI_inflections_MFT(predictor,data)\n",
        "print(f\"Failure rate: {failure_rate}. Total number of tests: {len(data)}\")\n",
        "append_to_results(results_path,{\"slang_verbs\":failure_rate})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data=json.load(open(path+\"new_verbs.json\"))\n",
        "failure_rate=evaluate_PI_inflections_MFT(predictor,data)\n",
        "print(f\"Failure rate: {failure_rate}. Total number of tests: {len(data)}\")\n",
        "append_to_results(results_path,{\"new_verbs\":failure_rate})\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pit7Ny7mvwL7"
      },
      "source": [
        "# AROUGMENTS CLASSIFICATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "#In this folder we have the data for the predicate classidication task. Change the path accordingly if files were moved.\n",
        "path=\"./Data/Argument_classification/\"\n",
        "results_path=f\"./results_{model}_Argument_Classification.json\"\n",
        "## we initialize also the dictionary that will contain the results\n",
        "with open(results_path, 'w') as f:\n",
        "    json.dump({\"test\":\"failure_rate\"},f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def eval_predictor_INV(sentences,predictor,function):\n",
        "  \"\"\"\n",
        "  This function evaluates the predictor by using the function to validate the predictions.\n",
        "  function is the name a function that takes two predictions and returns a boolean\n",
        "  \"\"\"\n",
        "  fails=0\n",
        " \n",
        "  f = getattr(utils, function)\n",
        "  for pair in sentences:\n",
        "    \n",
        "    s1,s2=pair\n",
        "\n",
        "    pred1 = predictor.predict(s1)\n",
        "    pred2 = predictor.predict(s2) \n",
        "    \n",
        "    match=f(pred1,pred2,verbose=False)\n",
        "    \n",
        "    if not (match):\n",
        "      fails+=1\n",
        "\n",
        "  return (fails/len(sentences)*100)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VsPA8Ym1P-Qj"
      },
      "source": [
        "## VOCABULAIRTY+POS"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xura9sS5eOrc"
      },
      "source": [
        "### Pronouns vs Entity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(path+\"Pronouns_sents.json\",\"r\") as f:\n",
        "    sentences=json.load(f)\n",
        "\n",
        "sentences=list(sentences.items())\n",
        "\n",
        "failure_rate=eval_predictor_INV(sentences,predictor,\"validate_INV_allverbs_ARGset\") #can try to do wit the othe function\n",
        "\n",
        "print(f\"Failure rate: {failure_rate}. Total number of tests: {len(sentences)}\")\n",
        "\n",
        "append_to_results(results_path,{f\"Pronouns_sents\":failure_rate})\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## AMBIGUITY/TAXONOMY (PP-ATTACHMENT AMBIGUITY)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PP-ATTACHMENT AMBIGUITY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentences=\"I went to the resturant by the Hutsin\", \"I went to the resturant by\"\n",
        "[\"I fixed the car with a red logo\",\"I fixed the car with a wretch\"]\n",
        "[\"I bought a computer with GPU\",\" I bought a computer wit bitcoins\"]\n",
        "\n",
        "for s in sentences:\n",
        "  print(s)\n",
        "  pred=predictor.predict(s)\n",
        "  desc=[x['description'] for x in pred['verbs']]\n",
        "  #print(verbs)\n",
        "  print(desc)\n",
        "  print(\"\\n\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'verbs': [{'verb': 'killed',\n",
              "   'description': '[ARG0: I] [V: killed] [ARG1: a rabbit] [ARG2: with a knife]',\n",
              "   'tags': ['B-ARG0',\n",
              "    'B-V',\n",
              "    'B-ARG1',\n",
              "    'I-ARG1',\n",
              "    'B-ARG2',\n",
              "    'I-ARG2',\n",
              "    'I-ARG2']}],\n",
              " 'words': ['I', 'killed', 'a', 'rabbit', 'with', 'a', 'knife']}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred=predictor_Bert.predict(\"I killed a rabbit with a knife\")\n",
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'verbs': [{'verb': 'eats',\n",
              "   'description': '[ARG0: Alice] [V: eats] [ARG1: a chicken] [ARGM-MNR: with a fork] .',\n",
              "   'tags': ['B-ARG0',\n",
              "    'B-V',\n",
              "    'B-ARG1',\n",
              "    'I-ARG1',\n",
              "    'B-ARGM-MNR',\n",
              "    'I-ARGM-MNR',\n",
              "    'I-ARGM-MNR',\n",
              "    'O']}],\n",
              " 'words': ['Alice', 'eats', 'a', 'chicken', 'with', 'a', 'fork', '.']}"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred=predictor_Bert.predict(\"Alice eats a chicken with a fork.\")\n",
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'verbs': [{'verb': 'eats', 'description': '[ARG0: Lukas] [V: eats] [ARG1: a chicken with a feather] .', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'O']}], 'words': ['Lukas', 'eats', 'a', 'chicken', 'with', 'a', 'feather', '.']}\n",
            "{'verbs': [{'verb': 'eats', 'description': '[ARG0: Lukas] [V: eats] [ARG1: a chicken] [ARGM-MNR: with a stick] .', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'B-ARGM-MNR', 'I-ARGM-MNR', 'I-ARGM-MNR', 'O']}], 'words': ['Lukas', 'eats', 'a', 'chicken', 'with', 'a', 'stick', '.']}\n"
          ]
        }
      ],
      "source": [
        "s=['Lukas eats a chicken with a feather.', 'Lukas eats a chicken with a stick.']\n",
        "for x in s:\n",
        "    pred=predictor_Bert.predict(x)\n",
        "    print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'verbs': [{'verb': 'eats', 'description': '[ARG0: Lukas] [V: eats] [ARG1: a chicken] [ARGM-MNR: with hands] .', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'B-ARGM-MNR', 'I-ARGM-MNR', 'O']}], 'words': ['Lukas', 'eats', 'a', 'chicken', 'with', 'hands', '.']}\n",
            "{'verbs': [{'verb': 'eats', 'description': '[ARG0: Lukas] [V: eats] [ARG1: a chicken with olives] .', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'O']}], 'words': ['Lukas', 'eats', 'a', 'chicken', 'with', 'olives', '.']}\n"
          ]
        }
      ],
      "source": [
        "s=['Lukas eats a chicken with hands.', 'Lukas eats a chicken with olives.']\n",
        "for x in s:\n",
        "    pred=predictor_Bert.predict(x)\n",
        "    print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'verbs': [{'verb': 'eats', 'description': '[ARG0: Lukas] [V: eats] [ARG1: a chicken] [ARG2: with tomatoes] .', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'B-ARG2', 'I-ARG2', 'O']}], 'words': ['Lukas', 'eats', 'a', 'chicken', 'with', 'tomatoes', '.']}\n",
            "{'verbs': [{'verb': 'eats', 'description': '[ARG0: Lukas] [V: eats] [ARG1: a chicken] [ARGM-MNR: with forks] .', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'B-ARGM-MNR', 'I-ARGM-MNR', 'O']}], 'words': ['Lukas', 'eats', 'a', 'chicken', 'with', 'forks', '.']}\n"
          ]
        }
      ],
      "source": [
        "s=['Lukas eats a chicken with tomatoes.', 'Lukas eats a chicken with forks.']\n",
        "for x in s:\n",
        "    pred=predictor_Bert.predict(x)\n",
        "    print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'verbs': [{'verb': 'drink', 'description': '[ARG0: I] [V: drink] [ARG1: whisky] [ARGM-MNR: with Ice]', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'B-ARGM-MNR', 'I-ARGM-MNR']}], 'words': ['I', 'drink', 'whisky', 'with', 'Ice']}\n",
            "{'verbs': [{'verb': 'drink', 'description': '[ARG0: I] [V: drink] [ARG1: wiskey] [ARGM-COM: with Jhon]', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'B-ARGM-COM', 'I-ARGM-COM']}], 'words': ['I', 'drink', 'wiskey', 'with', 'Jhon']}\n"
          ]
        }
      ],
      "source": [
        "s=['I drink whisky with Ice', 'I drink wiskey with Jhon']\n",
        "for x in s:\n",
        "    pred=predictor_Bert.predict(x)\n",
        "    print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'verbs': [{'verb': 'have', 'description': '[ARG0: I] [V: have] [ARG1: breakfast] [ARGM-MNR: with Coffee]', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'B-ARGM-MNR', 'I-ARGM-MNR']}], 'words': ['I', 'have', 'breakfast', 'with', 'Coffee']}\n",
            "{'verbs': [{'verb': 'have', 'description': '[ARG0: I] [V: have] [ARG1: breakfast] [ARGM-COM: with Sunny]', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'B-ARGM-COM', 'I-ARGM-COM']}], 'words': ['I', 'have', 'breakfast', 'with', 'Sunny']}\n"
          ]
        }
      ],
      "source": [
        "s=['I have breakfast with Coffee', 'I have breakfast with Sunny']\n",
        "for x in s:\n",
        "    pred=predictor_Bert.predict(x)\n",
        "    print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'verbs': [{'verb': 'come', 'description': '[ARG1: I] [V: come] [ARGM-MNR: by bike]', 'tags': ['B-ARG1', 'B-V', 'B-ARGM-MNR', 'I-ARGM-MNR']}], 'words': ['I', 'come', 'by', 'bike']}\n",
            "{'verbs': [{'verb': 'come', 'description': '[ARG1: I] [V: come] [ARGM-TMP: by noon]', 'tags': ['B-ARG1', 'B-V', 'B-ARGM-TMP', 'I-ARGM-TMP']}], 'words': ['I', 'come', 'by', 'noon']}\n"
          ]
        }
      ],
      "source": [
        "s=['I come by bike', 'I come by noon']\n",
        "for x in s:\n",
        "    pred=predictor_Bert.predict(x)\n",
        "    print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'verbs': [{'verb': 'saw', 'description': '[ARG0: Lukas] [V: saw] [ARG1: a man with a knife]', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1']}], 'words': ['Lukas', 'saw', 'a', 'man', 'with', 'a', 'knife']}\n",
            "{'verbs': [{'verb': 'saw', 'description': '[ARG0: Lukas] [V: saw] [ARG1: a man] [ARGM-MNR: with binoculars]', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'B-ARGM-MNR', 'I-ARGM-MNR']}], 'words': ['Lukas', 'saw', 'a', 'man', 'with', 'binoculars']}\n"
          ]
        }
      ],
      "source": [
        "s=['Lukas saw a man with a knife', 'Lukas saw a man with binoculars']\n",
        "for x in s:\n",
        "    pred=predictor_Bert.predict(x)\n",
        "    print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'verbs': [{'verb': 'having', 'description': '[ARG0: Lukas] [V: having] [ARG1: a beer] [ARGM-COM: with a friend] .', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'B-ARGM-COM', 'I-ARGM-COM', 'I-ARGM-COM', 'O']}], 'words': ['Lukas', 'having', 'a', 'beer', 'with', 'a', 'friend', '.']}\n",
            "{'verbs': [{'verb': 'having', 'description': '[ARG0: Lukas] [V: having] [ARG1: a beer] [ARG2: with a lemon] .', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'B-ARG2', 'I-ARG2', 'I-ARG2', 'O']}], 'words': ['Lukas', 'having', 'a', 'beer', 'with', 'a', 'lemon', '.']}\n"
          ]
        }
      ],
      "source": [
        "s=[\"Lukas having a beer with a friend.\",\"Lukas having a beer with a lemon.\"]\n",
        "for x in s:\n",
        "    pred=predictor_Bert.predict(x)\n",
        "    print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'verbs': [{'verb': 'helps', 'description': '[ARG0: Lukas] [V: helps] [ARG2: a man with a disability] .', 'tags': ['B-ARG0', 'B-V', 'B-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'O']}], 'words': ['Lukas', 'helps', 'a', 'man', 'with', 'a', 'disability', '.']}\n",
            "{'verbs': [{'verb': 'helps', 'description': '[ARG0: Lukas] [V: helps] [ARG2: a man] [ARG1: with a task] .', 'tags': ['B-ARG0', 'B-V', 'B-ARG2', 'I-ARG2', 'B-ARG1', 'I-ARG1', 'I-ARG1', 'O']}], 'words': ['Lukas', 'helps', 'a', 'man', 'with', 'a', 'task', '.']}\n"
          ]
        }
      ],
      "source": [
        "s=[\"Lukas helps a man with a disability.\",\"Lukas helps a man with a task.\"]\n",
        "for x in s:\n",
        "    pred=predictor_Bert.predict(x)\n",
        "    print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SPAN IDENTIFICATION"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LONG NER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def eval_NER(sentences,predictor):\n",
        "    fails=0\n",
        "    golden=['B-ARG0', 'I-ARG0', 'I-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'I-ARG1', 'B-ARGM-LOC', 'I-ARGM-LOC']\n",
        "    for s in sentences:\n",
        "        pred=predictor.predict(s)\n",
        "        success=check_NER_tags(pred,golden)\n",
        "        if not success:\n",
        "            fails+=1\n",
        "    return fails/len(sentences)*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failure rate: 67.0. Total number of tests: 100\n"
          ]
        }
      ],
      "source": [
        "\n",
        "with open(path+\"NER_sentences.json\",\"r\") as f:\n",
        "    di=json.load(f)\n",
        "\n",
        "golden=list(di.keys())[0]\n",
        "sentences=di[golden]\n",
        "golden=['B-ARG0', 'I-ARG0', 'I-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'I-ARG1', 'B-ARGM-LOC', 'I-ARGM-LOC']\n",
        "rate=eval_NER(sentences,predictor)\n",
        "print(f\"Failure rate: {rate}. Total number of tests: {len(sentences)}\")\n",
        "append_to_results(results_path,{f\"NER_sents\":rate})\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LONG SPAN ADJECTIVES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "djlQjIyAQIjV"
      },
      "source": [
        "## ROBUSTNESS"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Typos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(1,5):#becuase we have 4 files like that\n",
        "\n",
        "    with open(path+f\"sents_{i}_typos.json\", 'r') as f:\n",
        "        sentences = json.load(f)\n",
        "\n",
        "    sentences=list(sentences.items())\n",
        "\n",
        "    rate_typos_n=eval_predictor_INV(sentences,predictor,\"evaluate_INV_alltags\")\n",
        "\n",
        "    print(f\"Rate of failure with {i} typos per sentence: \",rate_typos_n)\n",
        "\n",
        "    append_to_results(results_path,{f\"sents_{i}_typos\":rate_typos_n})\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PARAPHRASING"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hGIRP7dVbw_W"
      },
      "source": [
        "### passive and actrive trasnformarion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "different arguments\n",
            "different arguments\n",
            "different arguments\n",
            "different arguments\n",
            "different arguments\n",
            "Rate of failure with for INV activepassive  21.73913043478261\n"
          ]
        }
      ],
      "source": [
        "with open(path+\"activepassive_sentences.json\", 'r') as f:\n",
        "    sentences = json.load(f)\n",
        "\n",
        "sentences=list(sentences.items())\n",
        "\n",
        "rate=eval_predictor_INV(sentences,predictor,\"evaluate_INV_sameArgs\")\n",
        "\n",
        "print(f\"Rate of failure with for INV activepassive \",rate)\n",
        "\n",
        "append_to_results(results_path,{f\"activepassive_sents\":rate})\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zfvIn-8biqxc"
      },
      "source": [
        "### Questions phrasing\n",
        "Idea for testing is to take all the arguments from from the verb that is the same(not the auxialiry).\n",
        " All the arguments should be the same except for the verb."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "different arguments\n",
            "Rate of failure with for INV in question rephrasing task  7.142857142857142\n"
          ]
        }
      ],
      "source": [
        "with open(path+\"question_rephrase.json\", 'r') as f:\n",
        "    sentences = json.load(f)\n",
        "\n",
        "sentences=list(sentences.items())\n",
        "\n",
        "rate=eval_predictor_INV(sentences,predictor,\"evaluate_INV_sameArgs\")\n",
        "\n",
        "print(f\"Rate of failure with for INV in question rephrasing task \",rate)\n",
        "\n",
        "append_to_results(results_path,{f\"question_rephrase\":rate})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\npred1=predictor_Bert.predict(\"It annoys me the results of the election\")\\npred1\\n\\n\\npred=predictor_Bert.predict(\"It Is great the results of the election\")\\npred\\n\\npred=predictor_Bert.predict(\"He was the one that did not want to go to the party\")\\nfor v in pred[\\'verbs\\']:\\n  print(v[\\'description\\'])\\n  \\n\\npred=predictor_Bert.predict(\"she is the sister that likes milk\")\\nfor v in pred[\\'verbs\\']:\\n  print(v[\\'description\\'])\\n  \\n\\nrelative_pronouns = {\\n    \"who\": \"The person who stole my bike was caught by the police.\",\\n    \"whom\": \"The woman whom I saw at the store was carrying a lot of groceries.\",\\n    \"which\": \"The car which I rented for my vacation was very comfortable.\",\\n    \"whose\": \"The man whose wallet was lost reported the incident to the authorities.\",\\n    \"where\": \"The park where we had our picnic was very peaceful.\",\\n    \"when\": \"The time when we first met is a very special memory for me.\",\\n    \"that\": \"The book that I\\'m reading right now is very suspenseful.\",\\n    \"whoever\": \"Whoever finishes first gets a prize.\",\\n    \"whichever\": \"You can choose whichever movie you want to see.\",\\n}\\nfor x in relative_pronouns:\\n  print(x)\\n  pred=predictor_Bert.predict(relative_pronouns[x])\\n  for v in pred[\\'verbs\\']:\\n    print(v[\\'description\\'])\\n  \\npred=predictor_Bert.predict(\"The partner of the lady, who is very old, has exacly my t-shirt\")\\npred\\npred[\\'verbs\\'][0][\\'description\\']\\n\\npred=predictor_Bert.predict(\"The partner of the lady who is very old, has exacly my t-shirt\")\\npred\\npred[\\'verbs\\'][0][\\'description\\']\\n\\npred=predictor_Bert.predict(\"The partner of the lady who is very old has exacly my t-shirt\")\\npred\\npred[\\'verbs\\'][0][\\'description\\']\\npred=predictor_Bert.predict(\"The cars in the shop which is expensive, are exacly what i dream\")\\npred\\npred[\\'verbs\\'][0][\\'description\\']\\n\\nOk so the idea is the coreference u dont need here becuase SRL is sentence based very much and for every predicate\\nyou have a sentence. So the coreference is not needed. But sometimes you have that in the same sentence.\\n'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "pred1=predictor_Bert.predict(\"It annoys me the results of the election\")\n",
        "pred1\n",
        "\n",
        "\n",
        "pred=predictor_Bert.predict(\"It Is great the results of the election\")\n",
        "pred\n",
        "\n",
        "pred=predictor_Bert.predict(\"He was the one that did not want to go to the party\")\n",
        "for v in pred['verbs']:\n",
        "  print(v['description'])\n",
        "  \n",
        "\n",
        "pred=predictor_Bert.predict(\"she is the sister that likes milk\")\n",
        "for v in pred['verbs']:\n",
        "  print(v['description'])\n",
        "  \n",
        "\n",
        "relative_pronouns = {\n",
        "    \"who\": \"The person who stole my bike was caught by the police.\",\n",
        "    \"whom\": \"The woman whom I saw at the store was carrying a lot of groceries.\",\n",
        "    \"which\": \"The car which I rented for my vacation was very comfortable.\",\n",
        "    \"whose\": \"The man whose wallet was lost reported the incident to the authorities.\",\n",
        "    \"where\": \"The park where we had our picnic was very peaceful.\",\n",
        "    \"when\": \"The time when we first met is a very special memory for me.\",\n",
        "    \"that\": \"The book that I'm reading right now is very suspenseful.\",\n",
        "    \"whoever\": \"Whoever finishes first gets a prize.\",\n",
        "    \"whichever\": \"You can choose whichever movie you want to see.\",\n",
        "}\n",
        "for x in relative_pronouns:\n",
        "  print(x)\n",
        "  pred=predictor_Bert.predict(relative_pronouns[x])\n",
        "  for v in pred['verbs']:\n",
        "    print(v['description'])\n",
        "  \n",
        "pred=predictor_Bert.predict(\"The partner of the lady, who is very old, has exacly my t-shirt\")\n",
        "pred\n",
        "pred['verbs'][0]['description']\n",
        "\n",
        "pred=predictor_Bert.predict(\"The partner of the lady who is very old, has exacly my t-shirt\")\n",
        "pred\n",
        "pred['verbs'][0]['description']\n",
        "\n",
        "pred=predictor_Bert.predict(\"The partner of the lady who is very old has exacly my t-shirt\")\n",
        "pred\n",
        "pred['verbs'][0]['description']\n",
        "pred=predictor_Bert.predict(\"The cars in the shop which is expensive, are exacly what i dream\")\n",
        "pred\n",
        "pred['verbs'][0]['description']\n",
        "\n",
        "Ok so the idea is the coreference u dont need here becuase SRL is sentence based very much and for every predicate\n",
        "you have a sentence. So the coreference is not needed. But sometimes you have that in the same sentence.\n",
        "\"\"\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "88Z28UZUr6NW"
      },
      "source": [
        "#### PP -ambiguity\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__UUhlKKi0II",
        "outputId": "df279aeb-590e-497c-9510-393de9163699"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I went to the resturant by the Hutsin\n",
            "['[ARG0: I] [V: went] [ARG4: to the resturant by the Hutsin]']\n",
            "\n",
            "\n",
            "\n",
            "I went to the resturant by bike\n",
            "['[ARG0: I] [V: went] [ARG4: to the resturant] [ARGM-MNR: by bike]']\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqHUwgoCr7OA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7i47oLC8qoSV"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "18hqUeT2Yije"
      },
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AsWFgLOtBAOh"
      },
      "source": [
        "# The cimitery of tests... [DONT RUN]\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qywAgrXmqR8S"
      },
      "source": [
        "### INCISI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIVdwIEqTDI",
        "outputId": "d2fc01e9-3d77-4c96-ef0c-a1aa102d3f19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This, friend, is epic \n",
            "['[ARG1: This ,] [ARGM-DIS: friend] , [V: is] [ARG2: epic]']\n",
            "\n",
            "\n",
            "\n",
            "This friend is epic\n",
            "['[ARG1: This friend] [V: is] [ARG2: epic]']\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sentences=[\"This, friend, is epic \",\"This friend is epic\"]\n",
        "for s in sentences:\n",
        "  print(s)\n",
        "  pred=predictor_Bert.predict(s)\n",
        "  desc=[x['description'] for x in pred['verbs']]\n",
        "  #print(verbs)\n",
        "  print(desc)\n",
        "  print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFQzrpEHqajZ"
      },
      "outputs": [],
      "source": [
        "(I might stay, tonight, with you)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1qa_YDiogvoa"
      },
      "source": [
        "### DIfferent frames for labels recognition\n",
        "With mutiple verbs, argoument confusion "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JoQIAH4WY2Kl"
      },
      "source": [
        "### Saxon genitive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqJO-kASY35h"
      },
      "outputs": [],
      "source": [
        "paired_sentences = [    [\"The president's decision to withdraw troops from the region caused controversy among military leaders.\",      \"The decision of the president to withdraw troops from the region caused controversy among military leaders.\"],\n",
        "    [\"The CEO's success in turning around the struggling company was due in large part to her innovative marketing strategies.\",      \"The success of the CEO in turning around the struggling company was due in large part to her innovative marketing strategies.\"],\n",
        "    [\"The director's vision for the film was not fully realized due to budget constraints and scheduling conflicts.\",      \"The vision of the director for the film was not fully realized due to budget constraints and scheduling conflicts.\"],\n",
        "    [\"The professor's lecture on the history of ancient Rome was attended by a packed auditorium of eager students.\",      \"The lecture on the history of ancient Rome of the professor was attended by a packed auditorium of eager students.\"],\n",
        "    [\"The artist's latest work, a sculpture made entirely of recycled materials, was featured in a prominent gallery exhibition.\",      \"The latest work of the artist, a sculpture made entirely of recycled materials, was featured in a prominent gallery exhibition.\"],\n",
        "    [\"The athlete's rigorous training regimen and strict diet led to her record-breaking performance at the championship.\",      \"The rigorous training regimen and strict diet of the athlete led to her record-breaking performance at the championship.\"],\n",
        "    [\"The author's use of symbolism and metaphor in her novel added depth and complexity to the story.\",      \"The use of symbolism and metaphor in her novel of the author added depth and complexity to the story.\"]\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xA-tIuKeeFwl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3HiN4_geN9E"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bZmRzaqwSkTM"
      },
      "source": [
        "### Intransitive verbs"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Intransitive verbs can be tricky:\n",
        "So there Unaccusative and Uneragtive are intrasntivie verbs. The difference is that unergative the subject is considered an againt, initating the action. whereas unaccusative the subject is considered the patient of the action.\n",
        "Naomi worked [argent]\n",
        "Naomi fell  [theme/patinet]\n",
        "\n",
        "an MFT test can just intransitive verbs being used as transitive verbs.\n",
        "\n",
        "and a directionality test can be used to see if the model is able to recognize the difference between unergative and unaccusative verbs. \n",
        "like the butter melted - the butter smells\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U47CiSLSsia",
        "outputId": "eba4faa3-5a89-48aa-a482-9a951d02eb1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sun rises in the east.\n",
            "['[ARG1: The sun] [V: rises] [ARGM-LOC: in the east] .']\n",
            "\n",
            "\n",
            "\n",
            "He slept for 10 hours.\n",
            "['[ARG0: He] [V: slept] [ARGM-TMP: for 10 hours] .']\n",
            "\n",
            "\n",
            "\n",
            "They danced all night.\n",
            "['[ARG0: They] [V: danced] [ARGM-TMP: all night] .']\n",
            "\n",
            "\n",
            "\n",
            "The flowers bloomed in the spring.\n",
            "['[ARG0: The flowers] [V: bloomed] [ARGM-TMP: in the spring] .']\n",
            "\n",
            "\n",
            "\n",
            "The baby cried all night.\n",
            "['[ARG0: The baby] [V: cried] [ARGM-TMP: all night] .']\n",
            "\n",
            "\n",
            "\n",
            "The cat meowed loudly.\n",
            "['[ARG0: The cat] [V: meowed] [ARGM-MNR: loudly] .']\n",
            "\n",
            "\n",
            "\n",
            "The car stopped suddenly.\n",
            "['[ARG1: The car] [V: stopped] [ARGM-MNR: suddenly] .']\n",
            "\n",
            "\n",
            "\n",
            "She ran around the park.\n",
            "['[ARG0: She] [V: ran] [ARGM-DIR: around the park] .']\n",
            "\n",
            "\n",
            "\n",
            "The plane took off at 9 am.\n",
            "['[ARG1: The plane] [V: took] off [ARGM-TMP: at 9 am] .']\n",
            "\n",
            "\n",
            "\n",
            "The wind blew fiercely.\n",
            "['[ARG1: The wind] [V: blew] [ARGM-MNR: fiercely] .']\n",
            "\n",
            "\n",
            "\n",
            "The tree swayed in the wind.\n",
            "['[ARG1: The tree] [V: swayed] [ARGM-LOC: in the wind] .']\n",
            "\n",
            "\n",
            "\n",
            "The river flows downstream.\n",
            "['[ARG1: The river] [V: flows] [ARGM-DIR: downstream] .']\n",
            "\n",
            "\n",
            "\n",
            "The coffee brewed in the pot.\n",
            "['[ARG1: The coffee] [V: brewed] [ARGM-LOC: in the pot] .']\n",
            "\n",
            "\n",
            "\n",
            "The music played softly in the background.\n",
            "['[ARG1: The music] [V: played] [ARGM-MNR: softly] [ARGM-LOC: in the background] .']\n",
            "\n",
            "\n",
            "\n",
            "The bird chirped early in the morning.\n",
            "['[ARG0: The bird] [V: chirped] [ARGM-TMP: early in the morning] .']\n",
            "\n",
            "\n",
            "\n",
            "The children laughed and played.\n",
            "['[ARG0: The children] [V: laughed] and played .', '[ARG0: The children] laughed and [V: played] .']\n",
            "\n",
            "\n",
            "\n",
            "The fire crackled in the fireplace.\n",
            "['[ARG0: The fire] [V: crackled] [ARGM-LOC: in the fireplace] .']\n",
            "\n",
            "\n",
            "\n",
            "The leaves fell from the trees.\n",
            "['[ARG1: The leaves] [V: fell] [ARG3: from the trees] .']\n",
            "\n",
            "\n",
            "\n",
            "The boat sailed across the ocean.\n",
            "['[ARG0: The boat] [V: sailed] [ARGM-DIR: across the ocean] .']\n",
            "\n",
            "\n",
            "\n",
            "The train arrived at the station on time.\n",
            "['[ARG1: The train] [V: arrived] [ARG4: at the station] [ARGM-TMP: on time] .']\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for s in sentences:\n",
        "  print(s)\n",
        "  pred=predictor.predict(s)\n",
        "  desc=[x['description'] for x in pred['verbs']]\n",
        "  #print(verbs)\n",
        "  print(desc)\n",
        "  print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crDSij6dS3XA"
      },
      "outputs": [],
      "source": [
        "sentences = ['The snow fell gently from the sky.',\n",
        "             'She laughed uncontrollably at the joke.',\n",
        "             'The sun set over the horizon.',\n",
        "             'The children played happily in the park.',\n",
        "             'The fire burned brightly in the fireplace.',\n",
        "             'The wind howled outside the window.',\n",
        "             'The cake baked for an hour.',\n",
        "             'The door opened slowly.',\n",
        "             'The crowd cheered loudly at the concert.',\n",
        "             'The athlete ran around the track.',\n",
        "             'The tree grew tall and strong.',\n",
        "             'The river flowed peacefully.',\n",
        "             'The bird flew gracefully through the air.',\n",
        "             'The fish swam quickly in the water.',\n",
        "             'The dog barked loudly at the mailman.',\n",
        "             'The car drove smoothly down the road.',\n",
        "             'The plane flew high above the clouds.',\n",
        "             'The moon shone brightly in the sky.',\n",
        "             'The stars twinkled in the night sky.',\n",
        "             'The flowers swayed in the breeze.']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W15h4WVZJFj",
        "outputId": "4af66d47-d0cc-4f15-9b9f-0afd4dbded95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The snow fell gently from the sky.\n",
            "['[ARG1: The snow] [V: fell] [ARGM-MNR: gently] [ARG3: from the sky] .']\n",
            "\n",
            "\n",
            "\n",
            "She laughed uncontrollably at the joke.\n",
            "['[ARG0: She] [V: laughed] [ARGM-MNR: uncontrollably] [ARG2: at the joke] .']\n",
            "\n",
            "\n",
            "\n",
            "The sun set over the horizon.\n",
            "['[ARG1: The sun] [V: set] [ARG2: over the horizon] .']\n",
            "\n",
            "\n",
            "\n",
            "The children played happily in the park.\n",
            "['[ARG0: The children] [V: played] [ARGM-MNR: happily] [ARGM-LOC: in the park] .']\n",
            "\n",
            "\n",
            "\n",
            "The fire burned brightly in the fireplace.\n",
            "['[ARG1: The fire] [V: burned] [ARGM-MNR: brightly] [ARGM-LOC: in the fireplace] .']\n",
            "\n",
            "\n",
            "\n",
            "The wind howled outside the window.\n",
            "['[ARG0: The wind] [V: howled] [ARGM-LOC: outside the window] .']\n",
            "\n",
            "\n",
            "\n",
            "The cake baked for an hour.\n",
            "['[ARG1: The cake] [V: baked] [ARGM-TMP: for an hour] .']\n",
            "\n",
            "\n",
            "\n",
            "The door opened slowly.\n",
            "['[ARG1: The door] [V: opened] [ARGM-MNR: slowly] .']\n",
            "\n",
            "\n",
            "\n",
            "The crowd cheered loudly at the concert.\n",
            "['[ARG0: The crowd] [V: cheered] [ARGM-MNR: loudly] [ARG1: at the concert] .']\n",
            "\n",
            "\n",
            "\n",
            "The athlete ran around the track.\n",
            "['[ARG0: The athlete] [V: ran] [ARGM-DIR: around the track] .']\n",
            "\n",
            "\n",
            "\n",
            "The tree grew tall and strong.\n",
            "['[ARG1: The tree] [V: grew] [ARGM-PRD: tall and strong] .']\n",
            "\n",
            "\n",
            "\n",
            "The river flowed peacefully.\n",
            "['[ARG1: The river] [V: flowed] [ARGM-MNR: peacefully] .']\n",
            "\n",
            "\n",
            "\n",
            "The bird flew gracefully through the air.\n",
            "['[ARG0: The bird] [V: flew] [ARGM-MNR: gracefully] [ARGM-DIR: through the air] .']\n",
            "\n",
            "\n",
            "\n",
            "The fish swam quickly in the water.\n",
            "[]\n",
            "\n",
            "\n",
            "\n",
            "The dog barked loudly at the mailman.\n",
            "['[ARG0: The dog] [V: barked] [ARGM-MNR: loudly] [ARG2: at the mailman] .']\n",
            "\n",
            "\n",
            "\n",
            "The car drove smoothly down the road.\n",
            "['[ARG0: The car] [V: drove] [ARGM-MNR: smoothly] [ARG1: down the road] .']\n",
            "\n",
            "\n",
            "\n",
            "The plane flew high above the clouds.\n",
            "['[ARG1: The plane] [V: flew] [ARGM-LOC: high above the clouds] .']\n",
            "\n",
            "\n",
            "\n",
            "The moon shone brightly in the sky.\n",
            "['[ARG1: The moon] [V: shone] [ARGM-MNR: brightly] [ARGM-LOC: in the sky] .']\n",
            "\n",
            "\n",
            "\n",
            "The stars twinkled in the night sky.\n",
            "['[ARG1: The stars] [V: twinkled] [ARGM-LOC: in the night sky] .']\n",
            "\n",
            "\n",
            "\n",
            "The flowers swayed in the breeze.\n",
            "['[ARG1: The flowers] [V: swayed] [ARGM-LOC: in the breeze] .']\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for s in sentences:\n",
        "  print(s)\n",
        "  pred=predictor.predict(s)\n",
        "  desc=[x['description'] for x in pred['verbs']]\n",
        "  #print(verbs)\n",
        "  print(desc)\n",
        "  print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNLh24X7Z5zo",
        "outputId": "5e4fee14-f665-4f11-9c04-f26c35025ffc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'verbs': [{'verb': 'keep',\n",
              "   'description': '[ARG0: Many people] [V: keep] [ARG1: falling for this CON - GAME that lower taxes on the rich benefits everyone] .',\n",
              "   'tags': ['B-ARG0',\n",
              "    'I-ARG0',\n",
              "    'B-V',\n",
              "    'B-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'O']},\n",
              "  {'verb': 'falling',\n",
              "   'description': '[ARG1: Many people] keep [V: falling] [ARGM-PRP: for this CON - GAME that lower taxes on the rich benefits everyone] .',\n",
              "   'tags': ['B-ARG1',\n",
              "    'I-ARG1',\n",
              "    'O',\n",
              "    'B-V',\n",
              "    'B-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'O']}],\n",
              " 'words': ['Many',\n",
              "  'people',\n",
              "  'keep',\n",
              "  'falling',\n",
              "  'for',\n",
              "  'this',\n",
              "  'CON',\n",
              "  '-',\n",
              "  'GAME',\n",
              "  'that',\n",
              "  'lower',\n",
              "  'taxes',\n",
              "  'on',\n",
              "  'the',\n",
              "  'rich',\n",
              "  'benefits',\n",
              "  'everyone',\n",
              "  '.']}"
            ]
          },
          "execution_count": 161,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sent=\"Many people keep falling for this CON - GAME that lower taxes on the rich benefits everyone . \"\n",
        "predictor.predict(sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpYziEq6aAhf",
        "outputId": "bf89e4fd-b324-43fd-9fe2-22d18b2ec2e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'verbs': [{'verb': 'walked',\n",
              "   'description': '[ARG0: He] [V: walked] [ARG1: the dog] [ARGM-GOL: to the park and back] .',\n",
              "   'tags': ['B-ARG0',\n",
              "    'B-V',\n",
              "    'B-ARG1',\n",
              "    'I-ARG1',\n",
              "    'B-ARGM-GOL',\n",
              "    'I-ARGM-GOL',\n",
              "    'I-ARGM-GOL',\n",
              "    'I-ARGM-GOL',\n",
              "    'I-ARGM-GOL',\n",
              "    'O']}],\n",
              " 'words': ['He',\n",
              "  'walked',\n",
              "  'the',\n",
              "  'dog',\n",
              "  'to',\n",
              "  'the',\n",
              "  'park',\n",
              "  'and',\n",
              "  'back',\n",
              "  '.']}"
            ]
          },
          "execution_count": 163,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.predict(\"He walked the dog to the park and back.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPbWPYbidmKY",
        "outputId": "426766eb-8c35-4be3-e22f-afe03b575d44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'verbs': [{'verb': 'walked',\n",
              "   'description': '[ARG0: He] [V: walked] [ARGM-COM: with the dog] [ARGM-GOL: to the park and back] .',\n",
              "   'tags': ['B-ARG0',\n",
              "    'B-V',\n",
              "    'B-ARGM-COM',\n",
              "    'I-ARGM-COM',\n",
              "    'I-ARGM-COM',\n",
              "    'B-ARGM-GOL',\n",
              "    'I-ARGM-GOL',\n",
              "    'I-ARGM-GOL',\n",
              "    'I-ARGM-GOL',\n",
              "    'I-ARGM-GOL',\n",
              "    'O']}],\n",
              " 'words': ['He',\n",
              "  'walked',\n",
              "  'with',\n",
              "  'the',\n",
              "  'dog',\n",
              "  'to',\n",
              "  'the',\n",
              "  'park',\n",
              "  'and',\n",
              "  'back',\n",
              "  '.']}"
            ]
          },
          "execution_count": 164,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.predict(\"He walked with the dog to the park and back.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyRX4rLYdzje",
        "outputId": "65eaa0f1-1bca-4953-e0f5-2ae227c50313"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'verbs': [{'verb': 'see',\n",
              "   'description': '[ARG0: I] [V: see] [ARG1: a man with a telescope under his arm]',\n",
              "   'tags': ['B-ARG0',\n",
              "    'B-V',\n",
              "    'B-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1']}],\n",
              " 'words': ['I',\n",
              "  'see',\n",
              "  'a',\n",
              "  'man',\n",
              "  'with',\n",
              "  'a',\n",
              "  'telescope',\n",
              "  'under',\n",
              "  'his',\n",
              "  'arm']}"
            ]
          },
          "execution_count": 182,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.predict(\"I see a man with a telescope under his arm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9NCwD39fjDK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKENZLQKew3c",
        "outputId": "1e0d7a08-8386-4948-a908-01544f0742bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'verbs': [{'verb': 'took',\n",
              "   'description': '[ARG0: The plane] [V: took] [ARG1: a large turn]',\n",
              "   'tags': ['B-ARG0', 'I-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'I-ARG1']}],\n",
              " 'words': ['The', 'plane', 'took', 'a', 'large', 'turn']}"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.predict(\"The plane took a large turn\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parenthetical Elements "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM6/gtRwphs5tZvfVtQ94Aw",
      "collapsed_sections": [
        "GIkns01FKdQd",
        "McQzhKS4LCVk",
        "dY-h4bawK2Ky",
        "2ybvS9k6Bsin",
        "XbQEiiaFLHtT",
        "xura9sS5eOrc",
        "djlQjIyAQIjV",
        "vFvgduTVSxBn",
        "XzSt0hAmQcYJ",
        "x2IbgB-XRuWQ",
        "qywAgrXmqR8S",
        "LzgT37FWxTPY",
        "JoQIAH4WY2Kl",
        "bZmRzaqwSkTM"
      ],
      "include_colab_link": true,
      "mount_file_id": "1j1qfHJIwReXyO57Aq4uu12y1pKIrYqHv",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "nlptasks",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
