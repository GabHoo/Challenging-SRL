{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GabHoo/Challenging-SRL/blob/main/Test_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SETTING UP\n",
        "Run the following cells in the Settin Up section to be able to run any of the tests in this notebook with the two suggested models.  \n",
        "Change the current value for both model path according to your own models location. If No models are found they will be downloaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iDMzdKns-m8m"
      },
      "outputs": [],
      "source": [
        "# INSTALL AND IMPORTS\n",
        "\"\"\"\n",
        "pip install allennlp\n",
        "pip install allennlp-models\n",
        "pip install -U spaCy\n",
        "pip install checklist\n",
        "\"\"\"\n",
        "from allennlp.predictors import Predictor\n",
        "import allennlp_models.tagging\n",
        "\n",
        "import json\n",
        "import os\n",
        "from utils import *\n",
        "import utils\n",
        "import re\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Change the model here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model found!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SRL model was loaded succeffully !\n"
          ]
        }
      ],
      "source": [
        "#LOADING MODEL\n",
        "model=\"Bert\"\n",
        "\n",
        "if model==\"Bert\":\n",
        "    model_name=\"structured-prediction-srl-bert.2020.12.15.tar.gz\"\n",
        "    path_model=\"models/\"+model_name\n",
        "elif model==\"Bilstm\":\n",
        "    model_name=\"openie-model.2020.03.26.tar.gz\"\n",
        "    path_model=\"models/\"+model_name\n",
        "else:\n",
        "    print(\"Model not found!\")\n",
        "    exit()\n",
        "\n",
        "if os.path.exists(path_model):\n",
        "    print(\"Model found!\")\n",
        "    predictor = Predictor.from_path(path_model)\n",
        "else:\n",
        "    predictor = Predictor.from_path(\"https://storage.googleapis.com/\"+model_name)\n",
        "\n",
        "#TESTING IF THE MODELS ARE LOADED CORRECTLY\n",
        "\n",
        "pred=predictor.predict(\"SRL model was loaded succeffully!\")\n",
        "if pred :\n",
        "    print((\" \").join(pred['words'])) \n",
        "    "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bqIKaBdxF1NF"
      },
      "source": [
        "# Useful functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def append_to_results(results_path,your_result):\n",
        "    \"\"\"Add results to the score board. \n",
        "    your_Results neets to be a dictionary alraedy'\n",
        "    \"\"\"\n",
        "    if type(your_result) != dict:\n",
        "        print(\"your_result needs to be a dictionary!\")\n",
        "        return\n",
        "    \n",
        "    with open(results_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    data.update(your_result)\n",
        "\n",
        "    with open(results_path, 'w') as f:\n",
        "        json.dump(data, f,indent=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pWslkmPkPFcy"
      },
      "source": [
        "# PREDICATE IDENTIFICATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "#In this folder we have the data for the predicate classidication task. Change the path accordingly if files were moved.\n",
        "path=\"./Data/Predicate_identification/\"\n",
        "results_path=f\"./results_{model}_Predicate_Identification.json\"\n",
        "## we initialize also the dictionary that will contain the results\n",
        "with open(results_path, 'w') as f:\n",
        "    json.dump({\"test\":\"failure_rate\"},f)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PkrGLpJMKSwn"
      },
      "source": [
        "## VOCABULARY+POS"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cCOznqQ_N9-z"
      },
      "source": [
        "### Test for contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failure rate: 0.0. Total number of tests: 18\n"
          ]
        }
      ],
      "source": [
        "data=json.load(open(path+'contracted_predicates.json'))\n",
        "failure_rate=evaluate_PI_contractions_INV(predictor,data)\n",
        "print(f\"Failure rate: {failure_rate}. Total number of tests: {len(data)}\")\n",
        "append_to_results(results_path,{\"contractions\":failure_rate})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ldzmhpP_ODor"
      },
      "source": [
        "### Test for irregular inflections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failed for: Gary vext an innocent soul. did not detect vext\n",
            "\n",
            "Failure rate: 2.857142857142857. Total number of tests: 35\n"
          ]
        }
      ],
      "source": [
        "data=json.load(open(path+\"inflected_predicates.json\"))\n",
        "failure_rate=evaluate_PI_inflections_MFT(predictor,data)\n",
        "print(f\"Failure rate: {failure_rate}. Total number of tests: {len(data)}\")\n",
        "append_to_results(results_path,{\"inflected_sentences\":failure_rate})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ROBUTSTNESS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failed for: They aet a cool lot. did not detect aet\n",
            "\n",
            "Failure rate: 1.8867924528301887. Total number of tests: 53\n"
          ]
        }
      ],
      "source": [
        "data=json.load(open(path+\"verb_typos_sentence.json\"))\n",
        "failure_rate=evaluate_PI_inflections_MFT(predictor,data)\n",
        "print(f\"Failure rate: {failure_rate}. Total number of tests: {len(data)}\")\n",
        "append_to_results(results_path,{\"inflected_sentences\":failure_rate})\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GIkns01FKdQd"
      },
      "source": [
        "## AMBIGUITY"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "McQzhKS4LCVk"
      },
      "source": [
        "### Experiment with polysemic verbs [POLISEMIC]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37j2bwA3ipm6",
        "outputId": "f14e3a19-db36-42df-c068-3f451f7bd648"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failed for: I always turn left at the stop sign. ... left found as a verb \n",
            "Failure rate: 3.4482758620689653. Total number of tests: 29\n"
          ]
        }
      ],
      "source": [
        "data=json.load(open(path+'polysem_verbs_sentences.json'))\n",
        "failure_rate=evaluate_PI_Polysem_DIR(predictor,data)\n",
        "print(f\"Failure rate: {failure_rate}. Total number of tests: {len(data)}\")\n",
        "append_to_results(results_path,{\"polysemic_verbs\":failure_rate})\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dY-h4bawK2Ky"
      },
      "source": [
        "### Experiment with verbs being in different roles -ing [GERUNDS]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data=json.load(open(path+\"gerunds.json\"))\n",
        "failure_rate=find_roleset_MFT(data,predictor,verboose=True)\n",
        "print(f\"\\nFailure rate: {failure_rate}. Total number of tests: {len(data)}\")\n",
        "append_to_results(results_path,{\"gerunds\":failure_rate})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Su6lKFxWKnbO"
      },
      "source": [
        "## RARITY"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SLANG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data=json.load(open(path+\"verbs_slang.json\"))\n",
        "failure_rate=evaluate_PI_inflections_MFT(predictor,data)\n",
        "print(f\"Failure rate: {failure_rate}. Total number of tests: {len(data)}\")\n",
        "append_to_results(results_path,{\"slang_verbs\":failure_rate})\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### NEW WORDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data=json.load(open(path+\"new_verbs.json\"))\n",
        "failure_rate=evaluate_PI_inflections_MFT(predictor,data)\n",
        "print(f\"Failure rate: {failure_rate}. Total number of tests: {len(data)}\")\n",
        "append_to_results(results_path,{\"new_verbs\":failure_rate})\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pit7Ny7mvwL7"
      },
      "source": [
        "# AROUGMENTS CLASSIFICATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "#In this folder we have the data for the predicate classidication task. Change the path accordingly if files were moved.\n",
        "path=\"./Data/Argument_classification/\"\n",
        "results_path=f\"./results_{model}_Argument_Classification.json\"\n",
        "## we initialize also the dictionary that will contain the results\n",
        "with open(results_path, 'w') as f:\n",
        "    json.dump({\"test_name\":\"failure_rate\"},f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VsPA8Ym1P-Qj"
      },
      "source": [
        "## VOCABULAIRTY+POS"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xura9sS5eOrc"
      },
      "source": [
        "###  Entity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(path+f\"FirstNames_sents.json\", 'r') as f:\n",
        "        sentences = json.load(f)\n",
        "\n",
        "labels=sentences[\"labels\"]\n",
        "sentences=sentences['data']\n",
        "failure=eval_full_sent_BIOtags(sentences,labels,predictor,verbose=True)\n",
        "\n",
        "print(f\"\\nRate of failure: \",failure,\"Total number of example: \",len(sentences),\"\\n\")\n",
        "\n",
        "append_to_results(results_path,{f\"FistNames\":failure})\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pronouns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(path+f\"Pronouns_sents.json\", 'r') as f:\n",
        "        sentences = json.load(f)\n",
        "\n",
        "labels=sentences[\"labels\"]\n",
        "sentences=sentences['data']\n",
        "failure=eval_full_sent_BIOtags(sentences,labels,predictor,verbose=True)\n",
        "\n",
        "print(f\"\\nRate of failure: \",failure,\"Total number of example: \",len(sentences),\"\\n\")\n",
        "\n",
        "append_to_results(results_path,{f\"Pronouns\":failure})\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## AMBIGUITY/TAXONOMY (PP-ATTACHMENT AMBIGUITY)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PP-ATTACHMENT AMBIGUITY INV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(path+f\"Inv_PPattachments.json\", 'r') as f:\n",
        "        sentences = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "def eval_PP_INV(sentences,predictor,verbose=False):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the PP attachment  based on partial pos tags. Lables given are infact only the one of the PP\n",
        "    \"\"\"\n",
        "    failure=0\n",
        "    for c in sentences:\n",
        "        s1,s2=c.keys()\n",
        "        pred1=predictor.predict(s1)\n",
        "        pred2=predictor.predict(s2)\n",
        "        labels1=c[s1]\n",
        "        labels2=c[s2]\n",
        "        ll1=len(labels1)\n",
        "        ll2=len(labels2)\n",
        "        if pred1['verbs'][0]['tags'][-ll1:]!=labels1:\n",
        "            failure+=1\n",
        "            if verbose:\n",
        "                print(f\"Input sentences: {s1}\")\n",
        "                print(f\"Predicted labels for PP: {pred1['verbs'][0]['tags'][-ll1:]} but should have been {labels1}\")\n",
        "            continue\n",
        "        if pred2['verbs'][0]['tags'][-ll2:]!=labels2:\n",
        "            failure+=1\n",
        "            if verbose:                             \n",
        "                print(f\"Input sentences: {s2}\")\n",
        "                print(f\"Predicted labels for PP: {pred2['verbs'][0]['tags'][-ll2:]} but should have been {labels2}\")\n",
        "                      \n",
        "\n",
        "    return failure/len(sentences)*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input sentences: I fixed the car with a red logo\n",
            "Predicted labels for PP: ['B-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2'] but should have been ['I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1']\n",
            "Input sentences:  I bought a computer with bitcoins\n",
            "Predicted labels for PP: ['I-ARG1', 'I-ARG1'] but should have been ['B-ARGM-MNR', 'I-ARGM-MNR']\n",
            "Input sentences: I drink whiskey with soda\n",
            "Predicted labels for PP: ['B-ARGM-COM', 'I-ARGM-COM'] but should have been ['I-ARG1', 'I-ARG1']\n",
            "\n",
            "Rate of failure:  50.0 Total number of example:  6 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "rate=eval_PP_INV(sentences,predictor,verbose=True)\n",
        "print(f\"\\nRate of failure: \",rate,\"Total number of example: \",len(sentences),\"\\n\")\n",
        "append_to_results(results_path,{f\"PP_INV\":rate})\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Big PP test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1826\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "no verbs found\n",
            "\n",
            "Rate of failure:  45.18072289156627 Total number of example:  1826 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "with open(path+\"PP_proceesed_test.json\",\"r\") as f:\n",
        "    di=json.load(f)\n",
        "\n",
        "print(len(di))\n",
        "\n",
        "rate=eval_PP_MFT(di,predictor,verbose=False)\n",
        "print(f\"\\nRate of failure: \",rate,\"Total number of example: \",len(di),\"\\n\")\n",
        "append_to_results(results_path,{f\"PP_MFT\":rate})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SPAN IDENTIFICATION"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LONG NER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "with open(path+\"NER_sentences.json\",\"r\") as f:\n",
        "    di=json.load(f)\n",
        "\n",
        "golden=di['labels']\n",
        "sentences=di['data']\n",
        "\n",
        "rate=eval_full_sent_BIOtags(sentences,golden,predictor,verbose=False)\n",
        "print(f\"\\nFailure rate: {rate}. Total number of tests: {len(sentences)}\")\n",
        "append_to_results(results_path,{f\"NER_sents\":rate})\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LONG SPAN ADJECTIVES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def eval_spanDetection(sents,start_indx,end_indx,predictor,verbose=False):\n",
        "    \"\"\"\n",
        "    This function evaluates the span detection task. It takes as input a list of sentences, a list of labels, the start and end index of the span.\n",
        "    If all element between the index are not detected in the same span, is a failure.\n",
        "    returns failure rate.\n",
        "    \"\"\"\n",
        "    fails=0\n",
        "    for s in sents:\n",
        "        pred=predictor.predict(s)\n",
        "        preds=pred['verbs']\n",
        "        found=False\n",
        "        for p in preds: #looking for every predicate in the sentence\n",
        "            print(p)\n",
        "            span=p['tags'][start_indx:end_indx]\n",
        "            #print(span)\n",
        "            span=[x.split('-')[1] if x!='O' else 'O' for x in span]\n",
        "            print(span)\n",
        "            if len(set(span))==1: #if the span is all the same label\n",
        "                found=True\n",
        "            else:\n",
        "                continue\n",
        "        if found==False:\n",
        "            fails+=1\n",
        "            if verbose:\n",
        "                print(\"\\nThe span was never detected\")\n",
        "                print(pred)\n",
        "    return (fails/len(sents)*100)\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(path+\"longspan_sents.json\",\"r\") as f:\n",
        "    di=json.load(f)\n",
        "sents=di['data']\n",
        "sents=sents[:30]\n",
        "start,end=di[\"indexes\"]\n",
        "rate=eval_spanDetection(sents,start,end,predictor,verbose=True)\n",
        "print(f\"\\nFailure rate: {rate}. Total number of tests: {len(sents)}\")\n",
        "append_to_results(results_path,{f\"longspan\":rate})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'span' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m span\n",
            "\u001b[0;31mNameError\u001b[0m: name 'span' is not defined"
          ]
        }
      ],
      "source": [
        "span"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "djlQjIyAQIjV"
      },
      "source": [
        "## ROBUSTNESS"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Typos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(1,5):#becuase we have 4 files like that\n",
        "\n",
        "    with open(path+f\"sents_{i}_typos.json\", 'r') as f:\n",
        "        sentences = json.load(f)\n",
        "\n",
        "    labels=sentences.pop(\"labels\")\n",
        "    sentences=list(sentences.values())\n",
        "    rate_typos_n=eval_full_sent_BIOtags(sentences,labels,predictor,verbose=False)\n",
        "\n",
        "    print(f\"Rate of failure with {i} typos per sentence: \",rate_typos_n)\n",
        "\n",
        "    append_to_results(results_path,{f\"sents_{i}_typos\":rate_typos_n})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PARAPHRASING"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hGIRP7dVbw_W"
      },
      "source": [
        "### passive and active trasnformarion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error\n",
            "[ARG0: The waiter] [V: served] [ARG1: the meal] . != ['B-ARG0', 'I-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'O']\n",
            "[ARG2: The meal] was [V: served] [ARG0: by the waiter] . != ['B-ARG1', 'I-ARG1', 'O', 'B-V', 'B-ARG0', 'I-ARG0', 'I-ARG0', 'O']\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Rate of failure:  5.0 % Total number of example:  20 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "with open(path+\"activepassive_sentences.json\", 'r') as f:\n",
        "    sentences = json.load(f)\n",
        "\n",
        "\n",
        "labelsActive=sentences.pop(\"labelsActive\")\n",
        "labelsPassive=sentences.pop(\"labelsPassive\")\n",
        "\n",
        "rate=eval_full_sent_BIOtags_INV(sentences,labelsActive,labelsPassive,predictor,verbose=False)\n",
        "\n",
        "print(f\"\\nRate of failure: \",rate,\"% Total number of example: \",len(sentences),\"\\n\")\n",
        "\n",
        "append_to_results(results_path,{f\"ActivePassive\":rate})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqHUwgoCr7OA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7i47oLC8qoSV"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "18hqUeT2Yije"
      },
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AsWFgLOtBAOh"
      },
      "source": [
        "# The cimitery of tests... [DONT RUN]\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qywAgrXmqR8S"
      },
      "source": [
        "### INCISI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIVdwIEqTDI",
        "outputId": "d2fc01e9-3d77-4c96-ef0c-a1aa102d3f19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This, friend, is epic \n",
            "['[ARG1: This ,] [ARGM-DIS: friend] , [V: is] [ARG2: epic]']\n",
            "\n",
            "\n",
            "\n",
            "This friend is epic\n",
            "['[ARG1: This friend] [V: is] [ARG2: epic]']\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sentences=[\"This, friend, is epic \",\"This friend is epic\"]\n",
        "for s in sentences:\n",
        "  print(s)\n",
        "  pred=predictor_Bert.predict(s)\n",
        "  desc=[x['description'] for x in pred['verbs']]\n",
        "  #print(verbs)\n",
        "  print(desc)\n",
        "  print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFQzrpEHqajZ"
      },
      "outputs": [],
      "source": [
        "(I might stay, tonight, with you)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1qa_YDiogvoa"
      },
      "source": [
        "### DIfferent frames for labels recognition\n",
        "With mutiple verbs, argoument confusion "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JoQIAH4WY2Kl"
      },
      "source": [
        "### Saxon genitive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqJO-kASY35h"
      },
      "outputs": [],
      "source": [
        "paired_sentences = [    [\"The president's decision to withdraw troops from the region caused controversy among military leaders.\",      \"The decision of the president to withdraw troops from the region caused controversy among military leaders.\"],\n",
        "    [\"The CEO's success in turning around the struggling company was due in large part to her innovative marketing strategies.\",      \"The success of the CEO in turning around the struggling company was due in large part to her innovative marketing strategies.\"],\n",
        "    [\"The director's vision for the film was not fully realized due to budget constraints and scheduling conflicts.\",      \"The vision of the director for the film was not fully realized due to budget constraints and scheduling conflicts.\"],\n",
        "    [\"The professor's lecture on the history of ancient Rome was attended by a packed auditorium of eager students.\",      \"The lecture on the history of ancient Rome of the professor was attended by a packed auditorium of eager students.\"],\n",
        "    [\"The artist's latest work, a sculpture made entirely of recycled materials, was featured in a prominent gallery exhibition.\",      \"The latest work of the artist, a sculpture made entirely of recycled materials, was featured in a prominent gallery exhibition.\"],\n",
        "    [\"The athlete's rigorous training regimen and strict diet led to her record-breaking performance at the championship.\",      \"The rigorous training regimen and strict diet of the athlete led to her record-breaking performance at the championship.\"],\n",
        "    [\"The author's use of symbolism and metaphor in her novel added depth and complexity to the story.\",      \"The use of symbolism and metaphor in her novel of the author added depth and complexity to the story.\"]\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xA-tIuKeeFwl"
      },
      "outputs": [],
      "source": [
        "\n",
        "### Questions phrasing\n",
        "#Idea for testing is to take all the arguments from from the verb that is the same(not the auxialiry).\n",
        "# All the arguments should be the same except for the verb.\n",
        "with open(path+\"question_rephrase.json\", 'r') as f:\n",
        "    sentences = json.load(f)\n",
        "\n",
        "sentences=list(sentences.items())\n",
        "\n",
        "rate=eval_predictor_INV(sentences,predictor,\"evaluate_INV_sameArgs\")\n",
        "\n",
        "print(f\"Rate of failure with for INV in question rephrasing task \",rate)\n",
        "\n",
        "append_to_results(results_path,{f\"question_rephrase\":rate})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3HiN4_geN9E"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bZmRzaqwSkTM"
      },
      "source": [
        "### Intransitive verbs"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Intransitive verbs can be tricky:\n",
        "So there Unaccusative and Uneragtive are intrasntivie verbs. The difference is that unergative the subject is considered an againt, initating the action. whereas unaccusative the subject is considered the patient of the action.\n",
        "Naomi worked [argent]\n",
        "Naomi fell  [theme/patinet]\n",
        "\n",
        "an MFT test can just intransitive verbs being used as transitive verbs.\n",
        "\n",
        "and a directionality test can be used to see if the model is able to recognize the difference between unergative and unaccusative verbs. \n",
        "like the butter melted - the butter smells\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U47CiSLSsia",
        "outputId": "eba4faa3-5a89-48aa-a482-9a951d02eb1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sun rises in the east.\n",
            "['[ARG1: The sun] [V: rises] [ARGM-LOC: in the east] .']\n",
            "\n",
            "\n",
            "\n",
            "He slept for 10 hours.\n",
            "['[ARG0: He] [V: slept] [ARGM-TMP: for 10 hours] .']\n",
            "\n",
            "\n",
            "\n",
            "They danced all night.\n",
            "['[ARG0: They] [V: danced] [ARGM-TMP: all night] .']\n",
            "\n",
            "\n",
            "\n",
            "The flowers bloomed in the spring.\n",
            "['[ARG0: The flowers] [V: bloomed] [ARGM-TMP: in the spring] .']\n",
            "\n",
            "\n",
            "\n",
            "The baby cried all night.\n",
            "['[ARG0: The baby] [V: cried] [ARGM-TMP: all night] .']\n",
            "\n",
            "\n",
            "\n",
            "The cat meowed loudly.\n",
            "['[ARG0: The cat] [V: meowed] [ARGM-MNR: loudly] .']\n",
            "\n",
            "\n",
            "\n",
            "The car stopped suddenly.\n",
            "['[ARG1: The car] [V: stopped] [ARGM-MNR: suddenly] .']\n",
            "\n",
            "\n",
            "\n",
            "She ran around the park.\n",
            "['[ARG0: She] [V: ran] [ARGM-DIR: around the park] .']\n",
            "\n",
            "\n",
            "\n",
            "The plane took off at 9 am.\n",
            "['[ARG1: The plane] [V: took] off [ARGM-TMP: at 9 am] .']\n",
            "\n",
            "\n",
            "\n",
            "The wind blew fiercely.\n",
            "['[ARG1: The wind] [V: blew] [ARGM-MNR: fiercely] .']\n",
            "\n",
            "\n",
            "\n",
            "The tree swayed in the wind.\n",
            "['[ARG1: The tree] [V: swayed] [ARGM-LOC: in the wind] .']\n",
            "\n",
            "\n",
            "\n",
            "The river flows downstream.\n",
            "['[ARG1: The river] [V: flows] [ARGM-DIR: downstream] .']\n",
            "\n",
            "\n",
            "\n",
            "The coffee brewed in the pot.\n",
            "['[ARG1: The coffee] [V: brewed] [ARGM-LOC: in the pot] .']\n",
            "\n",
            "\n",
            "\n",
            "The music played softly in the background.\n",
            "['[ARG1: The music] [V: played] [ARGM-MNR: softly] [ARGM-LOC: in the background] .']\n",
            "\n",
            "\n",
            "\n",
            "The bird chirped early in the morning.\n",
            "['[ARG0: The bird] [V: chirped] [ARGM-TMP: early in the morning] .']\n",
            "\n",
            "\n",
            "\n",
            "The children laughed and played.\n",
            "['[ARG0: The children] [V: laughed] and played .', '[ARG0: The children] laughed and [V: played] .']\n",
            "\n",
            "\n",
            "\n",
            "The fire crackled in the fireplace.\n",
            "['[ARG0: The fire] [V: crackled] [ARGM-LOC: in the fireplace] .']\n",
            "\n",
            "\n",
            "\n",
            "The leaves fell from the trees.\n",
            "['[ARG1: The leaves] [V: fell] [ARG3: from the trees] .']\n",
            "\n",
            "\n",
            "\n",
            "The boat sailed across the ocean.\n",
            "['[ARG0: The boat] [V: sailed] [ARGM-DIR: across the ocean] .']\n",
            "\n",
            "\n",
            "\n",
            "The train arrived at the station on time.\n",
            "['[ARG1: The train] [V: arrived] [ARG4: at the station] [ARGM-TMP: on time] .']\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for s in sentences:\n",
        "  print(s)\n",
        "  pred=predictor.predict(s)\n",
        "  desc=[x['description'] for x in pred['verbs']]\n",
        "  #print(verbs)\n",
        "  print(desc)\n",
        "  print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crDSij6dS3XA"
      },
      "outputs": [],
      "source": [
        "sentences = ['The snow fell gently from the sky.',\n",
        "             'She laughed uncontrollably at the joke.',\n",
        "             'The sun set over the horizon.',\n",
        "             'The children played happily in the park.',\n",
        "             'The fire burned brightly in the fireplace.',\n",
        "             'The wind howled outside the window.',\n",
        "             'The cake baked for an hour.',\n",
        "             'The door opened slowly.',\n",
        "             'The crowd cheered loudly at the concert.',\n",
        "             'The athlete ran around the track.',\n",
        "             'The tree grew tall and strong.',\n",
        "             'The river flowed peacefully.',\n",
        "             'The bird flew gracefully through the air.',\n",
        "             'The fish swam quickly in the water.',\n",
        "             'The dog barked loudly at the mailman.',\n",
        "             'The car drove smoothly down the road.',\n",
        "             'The plane flew high above the clouds.',\n",
        "             'The moon shone brightly in the sky.',\n",
        "             'The stars twinkled in the night sky.',\n",
        "             'The flowers swayed in the breeze.']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W15h4WVZJFj",
        "outputId": "4af66d47-d0cc-4f15-9b9f-0afd4dbded95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The snow fell gently from the sky.\n",
            "['[ARG1: The snow] [V: fell] [ARGM-MNR: gently] [ARG3: from the sky] .']\n",
            "\n",
            "\n",
            "\n",
            "She laughed uncontrollably at the joke.\n",
            "['[ARG0: She] [V: laughed] [ARGM-MNR: uncontrollably] [ARG2: at the joke] .']\n",
            "\n",
            "\n",
            "\n",
            "The sun set over the horizon.\n",
            "['[ARG1: The sun] [V: set] [ARG2: over the horizon] .']\n",
            "\n",
            "\n",
            "\n",
            "The children played happily in the park.\n",
            "['[ARG0: The children] [V: played] [ARGM-MNR: happily] [ARGM-LOC: in the park] .']\n",
            "\n",
            "\n",
            "\n",
            "The fire burned brightly in the fireplace.\n",
            "['[ARG1: The fire] [V: burned] [ARGM-MNR: brightly] [ARGM-LOC: in the fireplace] .']\n",
            "\n",
            "\n",
            "\n",
            "The wind howled outside the window.\n",
            "['[ARG0: The wind] [V: howled] [ARGM-LOC: outside the window] .']\n",
            "\n",
            "\n",
            "\n",
            "The cake baked for an hour.\n",
            "['[ARG1: The cake] [V: baked] [ARGM-TMP: for an hour] .']\n",
            "\n",
            "\n",
            "\n",
            "The door opened slowly.\n",
            "['[ARG1: The door] [V: opened] [ARGM-MNR: slowly] .']\n",
            "\n",
            "\n",
            "\n",
            "The crowd cheered loudly at the concert.\n",
            "['[ARG0: The crowd] [V: cheered] [ARGM-MNR: loudly] [ARG1: at the concert] .']\n",
            "\n",
            "\n",
            "\n",
            "The athlete ran around the track.\n",
            "['[ARG0: The athlete] [V: ran] [ARGM-DIR: around the track] .']\n",
            "\n",
            "\n",
            "\n",
            "The tree grew tall and strong.\n",
            "['[ARG1: The tree] [V: grew] [ARGM-PRD: tall and strong] .']\n",
            "\n",
            "\n",
            "\n",
            "The river flowed peacefully.\n",
            "['[ARG1: The river] [V: flowed] [ARGM-MNR: peacefully] .']\n",
            "\n",
            "\n",
            "\n",
            "The bird flew gracefully through the air.\n",
            "['[ARG0: The bird] [V: flew] [ARGM-MNR: gracefully] [ARGM-DIR: through the air] .']\n",
            "\n",
            "\n",
            "\n",
            "The fish swam quickly in the water.\n",
            "[]\n",
            "\n",
            "\n",
            "\n",
            "The dog barked loudly at the mailman.\n",
            "['[ARG0: The dog] [V: barked] [ARGM-MNR: loudly] [ARG2: at the mailman] .']\n",
            "\n",
            "\n",
            "\n",
            "The car drove smoothly down the road.\n",
            "['[ARG0: The car] [V: drove] [ARGM-MNR: smoothly] [ARG1: down the road] .']\n",
            "\n",
            "\n",
            "\n",
            "The plane flew high above the clouds.\n",
            "['[ARG1: The plane] [V: flew] [ARGM-LOC: high above the clouds] .']\n",
            "\n",
            "\n",
            "\n",
            "The moon shone brightly in the sky.\n",
            "['[ARG1: The moon] [V: shone] [ARGM-MNR: brightly] [ARGM-LOC: in the sky] .']\n",
            "\n",
            "\n",
            "\n",
            "The stars twinkled in the night sky.\n",
            "['[ARG1: The stars] [V: twinkled] [ARGM-LOC: in the night sky] .']\n",
            "\n",
            "\n",
            "\n",
            "The flowers swayed in the breeze.\n",
            "['[ARG1: The flowers] [V: swayed] [ARGM-LOC: in the breeze] .']\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for s in sentences:\n",
        "  print(s)\n",
        "  pred=predictor.predict(s)\n",
        "  desc=[x['description'] for x in pred['verbs']]\n",
        "  #print(verbs)\n",
        "  print(desc)\n",
        "  print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNLh24X7Z5zo",
        "outputId": "5e4fee14-f665-4f11-9c04-f26c35025ffc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'verbs': [{'verb': 'keep',\n",
              "   'description': '[ARG0: Many people] [V: keep] [ARG1: falling for this CON - GAME that lower taxes on the rich benefits everyone] .',\n",
              "   'tags': ['B-ARG0',\n",
              "    'I-ARG0',\n",
              "    'B-V',\n",
              "    'B-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'O']},\n",
              "  {'verb': 'falling',\n",
              "   'description': '[ARG1: Many people] keep [V: falling] [ARGM-PRP: for this CON - GAME that lower taxes on the rich benefits everyone] .',\n",
              "   'tags': ['B-ARG1',\n",
              "    'I-ARG1',\n",
              "    'O',\n",
              "    'B-V',\n",
              "    'B-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'O']}],\n",
              " 'words': ['Many',\n",
              "  'people',\n",
              "  'keep',\n",
              "  'falling',\n",
              "  'for',\n",
              "  'this',\n",
              "  'CON',\n",
              "  '-',\n",
              "  'GAME',\n",
              "  'that',\n",
              "  'lower',\n",
              "  'taxes',\n",
              "  'on',\n",
              "  'the',\n",
              "  'rich',\n",
              "  'benefits',\n",
              "  'everyone',\n",
              "  '.']}"
            ]
          },
          "execution_count": 161,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sent=\"Many people keep falling for this CON - GAME that lower taxes on the rich benefits everyone . \"\n",
        "predictor.predict(sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpYziEq6aAhf",
        "outputId": "bf89e4fd-b324-43fd-9fe2-22d18b2ec2e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'verbs': [{'verb': 'walked',\n",
              "   'description': '[ARG0: He] [V: walked] [ARG1: the dog] [ARGM-GOL: to the park and back] .',\n",
              "   'tags': ['B-ARG0',\n",
              "    'B-V',\n",
              "    'B-ARG1',\n",
              "    'I-ARG1',\n",
              "    'B-ARGM-GOL',\n",
              "    'I-ARGM-GOL',\n",
              "    'I-ARGM-GOL',\n",
              "    'I-ARGM-GOL',\n",
              "    'I-ARGM-GOL',\n",
              "    'O']}],\n",
              " 'words': ['He',\n",
              "  'walked',\n",
              "  'the',\n",
              "  'dog',\n",
              "  'to',\n",
              "  'the',\n",
              "  'park',\n",
              "  'and',\n",
              "  'back',\n",
              "  '.']}"
            ]
          },
          "execution_count": 163,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.predict(\"He walked the dog to the park and back.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPbWPYbidmKY",
        "outputId": "426766eb-8c35-4be3-e22f-afe03b575d44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'verbs': [{'verb': 'walked',\n",
              "   'description': '[ARG0: He] [V: walked] [ARGM-COM: with the dog] [ARGM-GOL: to the park and back] .',\n",
              "   'tags': ['B-ARG0',\n",
              "    'B-V',\n",
              "    'B-ARGM-COM',\n",
              "    'I-ARGM-COM',\n",
              "    'I-ARGM-COM',\n",
              "    'B-ARGM-GOL',\n",
              "    'I-ARGM-GOL',\n",
              "    'I-ARGM-GOL',\n",
              "    'I-ARGM-GOL',\n",
              "    'I-ARGM-GOL',\n",
              "    'O']}],\n",
              " 'words': ['He',\n",
              "  'walked',\n",
              "  'with',\n",
              "  'the',\n",
              "  'dog',\n",
              "  'to',\n",
              "  'the',\n",
              "  'park',\n",
              "  'and',\n",
              "  'back',\n",
              "  '.']}"
            ]
          },
          "execution_count": 164,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.predict(\"He walked with the dog to the park and back.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyRX4rLYdzje",
        "outputId": "65eaa0f1-1bca-4953-e0f5-2ae227c50313"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'verbs': [{'verb': 'see',\n",
              "   'description': '[ARG0: I] [V: see] [ARG1: a man with a telescope under his arm]',\n",
              "   'tags': ['B-ARG0',\n",
              "    'B-V',\n",
              "    'B-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1']}],\n",
              " 'words': ['I',\n",
              "  'see',\n",
              "  'a',\n",
              "  'man',\n",
              "  'with',\n",
              "  'a',\n",
              "  'telescope',\n",
              "  'under',\n",
              "  'his',\n",
              "  'arm']}"
            ]
          },
          "execution_count": 182,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.predict(\"I see a man with a telescope under his arm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9NCwD39fjDK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKENZLQKew3c",
        "outputId": "1e0d7a08-8386-4948-a908-01544f0742bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'verbs': [{'verb': 'took',\n",
              "   'description': '[ARG0: The plane] [V: took] [ARG1: a large turn]',\n",
              "   'tags': ['B-ARG0', 'I-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'I-ARG1']}],\n",
              " 'words': ['The', 'plane', 'took', 'a', 'large', 'turn']}"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.predict(\"The plane took a large turn\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parenthetical Elements "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM6/gtRwphs5tZvfVtQ94Aw",
      "collapsed_sections": [
        "GIkns01FKdQd",
        "McQzhKS4LCVk",
        "dY-h4bawK2Ky",
        "2ybvS9k6Bsin",
        "XbQEiiaFLHtT",
        "xura9sS5eOrc",
        "djlQjIyAQIjV",
        "vFvgduTVSxBn",
        "XzSt0hAmQcYJ",
        "x2IbgB-XRuWQ",
        "qywAgrXmqR8S",
        "LzgT37FWxTPY",
        "JoQIAH4WY2Kl",
        "bZmRzaqwSkTM"
      ],
      "include_colab_link": true,
      "mount_file_id": "1j1qfHJIwReXyO57Aq4uu12y1pKIrYqHv",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "nlptasks",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
