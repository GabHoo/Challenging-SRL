{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GabHoo/Challenging-SRL/blob/main/Test_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SETTING UP\n",
        "Run the following cells in the Settin Up section to be able to run any of the tests in this notebook with the two suggested models.  \n",
        "Change the current value for both model path according to your own models location. If No models are found they will be downloaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iDMzdKns-m8m"
      },
      "outputs": [],
      "source": [
        "# INSTALL AND IMPORTS\n",
        "\"\"\"\n",
        "pip install allennlp\n",
        "pip install allennlp-models\n",
        "pip install -U spaCy\n",
        "pip install checklist\n",
        "\"\"\"\n",
        "from allennlp.predictors import Predictor\n",
        "import allennlp_models.tagging\n",
        "\n",
        "import json\n",
        "import os\n",
        "from utils import *\n",
        "import utils\n",
        "import re\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Change the model here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model found!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/gabhoo/.local/lib/python3.10/site-packages/spacy/util.py:887: UserWarning: [W095] Model 'en_core_web_sm' (3.3.0) was trained with spaCy v3.3 and may not be 100% compatible with the current version (3.5.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SRL model was loaded succeffully !\n"
          ]
        }
      ],
      "source": [
        "#LOADING MODEL\n",
        "model=\"Bilstm\"\n",
        "\n",
        "if model==\"Bert\":\n",
        "    model_name=\"structured-prediction-srl-bert.2020.12.15.tar.gz\"\n",
        "    path_model=\"models/\"+model_name\n",
        "elif model==\"Bilstm\":\n",
        "    model_name=\"openie-model.2020.03.26.tar.gz\"\n",
        "    path_model=\"models/\"+model_name\n",
        "else:\n",
        "    print(\"Model not found!\")\n",
        "    exit()\n",
        "\n",
        "if os.path.exists(path_model):\n",
        "    print(\"Model found!\")\n",
        "    predictor = Predictor.from_path(path_model)\n",
        "else:\n",
        "    predictor = Predictor.from_path(\"https://storage.googleapis.com/\"+model_name)\n",
        "\n",
        "#TESTING IF THE MODELS ARE LOADED CORRECTLY\n",
        "\n",
        "pred=predictor.predict(\"SRL model was loaded succeffully!\")\n",
        "if pred :\n",
        "    print((\" \").join(pred['words'])) \n",
        "    "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bqIKaBdxF1NF"
      },
      "source": [
        "# Useful functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def append_to_results(results_path,your_result):\n",
        "    \"\"\"Add results to the score board. \n",
        "    your_Results neets to be a dictionary alraedy'\n",
        "    \"\"\"\n",
        "    if type(your_result) != dict:\n",
        "        print(\"your_result needs to be a dictionary!\")\n",
        "        return\n",
        "    \n",
        "    with open(results_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    data.update(your_result)\n",
        "\n",
        "    with open(results_path, 'w') as f:\n",
        "        json.dump(data, f,indent=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pWslkmPkPFcy"
      },
      "source": [
        "# PREDICATE IDENTIFICATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "#In this folder we have the data for the predicate classidication task. Change the path accordingly if files were moved.\n",
        "path=\"./Data/Predicate_identification/\"\n",
        "results_path=f\"./results_{model}_Predicate_Identification.json\"\n",
        "## we initialize also the dictionary that will contain the results\n",
        "with open(results_path, 'w') as f:\n",
        "    json.dump({\"test\":\"failure_rate\"},f)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PkrGLpJMKSwn"
      },
      "source": [
        "## VOCABULARY+POS"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cCOznqQ_N9-z"
      },
      "source": [
        "### Test for contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failure rate: 0.0. Total number of tests: 18\n"
          ]
        }
      ],
      "source": [
        "data=json.load(open(path+'contracted_predicates.json'))\n",
        "failure_rate=evaluate_PI_contractions_INV(predictor,data)\n",
        "print(f\"Failure rate: {failure_rate}. Total number of tests: {len(data)}\")\n",
        "append_to_results(results_path,{\"contractions\":failure_rate})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ldzmhpP_ODor"
      },
      "source": [
        "### Test for irregular inflections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failed for: Gary vext an innocent soul. did not detect vext\n",
            "\n",
            "Failure rate: 2.857142857142857. Total number of tests: 35\n"
          ]
        }
      ],
      "source": [
        "data=json.load(open(path+\"inflected_predicates.json\"))\n",
        "failure_rate=evaluate_PI_inflections_MFT(predictor,data)\n",
        "print(f\"Failure rate: {failure_rate}. Total number of tests: {len(data)}\")\n",
        "append_to_results(results_path,{\"inflected_sentences\":failure_rate})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ROBUTSTNESS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failed for: They aet a cool lot. did not detect aet\n",
            "\n",
            "Failure rate: 1.8867924528301887. Total number of tests: 53\n"
          ]
        }
      ],
      "source": [
        "data=json.load(open(path+\"verb_typos_sentence.json\"))\n",
        "failure_rate=evaluate_PI_inflections_MFT(predictor,data)\n",
        "print(f\"Failure rate: {failure_rate}. Total number of tests: {len(data)}\")\n",
        "append_to_results(results_path,{\"inflected_sentences\":failure_rate})\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GIkns01FKdQd"
      },
      "source": [
        "## AMBIGUITY"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "McQzhKS4LCVk"
      },
      "source": [
        "### Experiment with polysemic verbs [POLISEMIC]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37j2bwA3ipm6",
        "outputId": "f14e3a19-db36-42df-c068-3f451f7bd648"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failed for: I always turn left at the stop sign. ... left found as a verb \n",
            "Failure rate: 3.4482758620689653. Total number of tests: 29\n"
          ]
        }
      ],
      "source": [
        "data=json.load(open(path+'polysem_verbs_sentences.json'))\n",
        "failure_rate=evaluate_PI_Polysem_DIR(predictor,data)\n",
        "print(f\"Failure rate: {failure_rate}. Total number of tests: {len(data)}\")\n",
        "append_to_results(results_path,{\"polysemic_verbs\":failure_rate})\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dY-h4bawK2Ky"
      },
      "source": [
        "### Experiment with verbs being in different roles -ing [GERUNDS]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[paitings] not detected from 'From paintings of his done during that early period', only ['done'] were found ['done']\n",
            "[writing] not detected from 'The writing of the thesis took a whole year.', only ['took'] were found ['took']\n",
            "[singning] not detected from 'The singing of the birds was a welcome sound in the morning.', only ['was'] were found ['was']\n",
            "[reading] not detected from 'What is your reading on the situation?', only ['is'] were found ['is']\n",
            "[cleaning] not detected from 'The cleaning of the house was a tedious chore.', only ['was'] were found ['was']\n",
            "[washing] not detected from 'The washing of the dishes was a never-ending job.', only ['was', 'ending'] were found ['was', 'ending']\n",
            "[cooking] not detected from 'I have always enjoyed cooking, it is one of my favourite hobbies.', only ['have', 'enjoyed', 'is'] were found ['have', 'enjoyed', 'is']\n",
            "[building] not detected from 'The building of the bridge was a remarkable feat of engineering.', only ['was'] were found ['was']\n",
            "[cutting] not detected from 'The cutting of the cake was the highlight of the party.', only ['was'] were found ['was']\n",
            "[killing] not detected from 'The protests that followed the killing of the priest were widespread.', only ['followed', 'were'] were found ['followed', 'were']\n",
            "[interesting] not detected from 'The movie was interesting to watch', only ['was', 'watch'] were found ['was', 'watch']\n",
            "Failure rate: 73.33333333333333. Total number of tests: 15\n"
          ]
        }
      ],
      "source": [
        "data=json.load(open(path+\"gerunds.json\"))\n",
        "failure_rate=find_roleset_MFT(data,predictor,verboose=True)\n",
        "print(f\"Failure rate: {failure_rate}. Total number of tests: {len(data)}\")\n",
        "append_to_results(results_path,{\"gerunds\":failure_rate})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Su6lKFxWKnbO"
      },
      "source": [
        "## RARITY"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SLANG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data=json.load(open(path+\"verbs_slang.json\"))\n",
        "failure_rate=evaluate_PI_inflections_MFT(predictor,data)\n",
        "print(f\"Failure rate: {failure_rate}. Total number of tests: {len(data)}\")\n",
        "append_to_results(results_path,{\"slang_verbs\":failure_rate})\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### NEW WORDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data=json.load(open(path+\"new_verbs.json\"))\n",
        "failure_rate=evaluate_PI_inflections_MFT(predictor,data)\n",
        "print(f\"Failure rate: {failure_rate}. Total number of tests: {len(data)}\")\n",
        "append_to_results(results_path,{\"new_verbs\":failure_rate})\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pit7Ny7mvwL7"
      },
      "source": [
        "# AROUGMENTS CLASSIFICATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "#In this folder we have the data for the predicate classidication task. Change the path accordingly if files were moved.\n",
        "path=\"./Data/Argument_classification/\"\n",
        "results_path=f\"./results_{model}_Argument_Classification.json\"\n",
        "## we initialize also the dictionary that will contain the results\n",
        "with open(results_path, 'w') as f:\n",
        "    json.dump({\"test\":\"failure_rate\"},f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def eval_full_sent_BIOtags(sents,labels,predictor,verb_indx=0,verbose=True): #verb_indx to 0 as it is often  the case that there is only one predicate\n",
        "    \"\"\"\n",
        "    This function evaluates the predictor by using the BIO tags of the predictions.\n",
        "    \"\"\"\n",
        "    fails=0\n",
        "    for s in sents:\n",
        "        #print(s)\n",
        "        pred = predictor.predict(s)\n",
        "        if not pred['verbs']: #no verb found\n",
        "            fails+=1\n",
        "            if verbose:\n",
        "                print(\"\\n FAILED FOR Sentence: \",s)\n",
        "                print(\"no verbs found \")\n",
        "            continue\n",
        "\n",
        "        if pred['verbs'][verb_indx]['tags'] != labels: #wrong prediction\n",
        "            fails+=1\n",
        "            if verbose:\n",
        "                print(\"\\n FAILED FOR Sentence: \",s)\n",
        "                print(\"Predicted BIO tags: \",pred['verbs'][verb_indx]['tags'])\n",
        "                print(\"True BIO tags: \",labels)\n",
        "          \n",
        "    return (fails/len(sents)*100)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VsPA8Ym1P-Qj"
      },
      "source": [
        "## VOCABULAIRTY+POS"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xura9sS5eOrc"
      },
      "source": [
        "###  Entity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " FAILED FOR Sentence:  Anthony went with Jennifer to the ball\n",
            "Predicted BIO tags:  ['B-ARG1', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Donald went with Adam to the funeral\n",
            "Predicted BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-MNR', 'I-ARGM-MNR', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Jill went with Stephanie to the opera\n",
            "Predicted BIO tags:  ['B-ARG1', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Sarah went with Louis to the school\n",
            "Predicted BIO tags:  ['B-ARG1', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Frances went with Robin to the parade\n",
            "Predicted BIO tags:  ['B-ARG1', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Don went with Stephen to the bank\n",
            "Predicted BIO tags:  ['B-ARG1', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Frank went with Philip to the castle\n",
            "Predicted BIO tags:  ['B-ARG1', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Maria went with George to the cemetery\n",
            "Predicted BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-MNR', 'I-ARGM-MNR', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Frances went with Edwin to the fair\n",
            "Predicted BIO tags:  ['B-ARG1', 'B-V', 'B-ARGM-MNR', 'I-ARGM-MNR', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Al went with Ralph to the hospital\n",
            "Predicted BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-MNR', 'I-ARGM-MNR', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Emily went with Anne to the parade\n",
            "Predicted BIO tags:  ['B-ARG1', 'B-V', 'B-ARGM-MNR', 'I-ARGM-MNR', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Henry went with Katie to the fundraiser\n",
            "Predicted BIO tags:  ['B-ARG1', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Steve went with Bobby to the theater\n",
            "Predicted BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-MNR', 'I-ARGM-MNR', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Victoria went with Ralph to the school\n",
            "Predicted BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-MNR', 'I-ARGM-MNR', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Anne went with Eleanor to the bookstore\n",
            "Predicted BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-MNR', 'I-ARGM-MNR', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Florence went with Albert to the supermarket\n",
            "Predicted BIO tags:  ['B-ARG1', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Henry went with Donald to the exhibit\n",
            "Predicted BIO tags:  ['B-ARG1', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Alfred went with Ben to the gym\n",
            "Predicted BIO tags:  ['B-ARGM-DIS', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Kim went with Emily to the car\n",
            "Predicted BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-MNR', 'I-ARGM-MNR', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Frances went with Hugh to the dance\n",
            "Predicted BIO tags:  ['B-ARG1', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Mark went with Jill to the Y\n",
            "Predicted BIO tags:  ['B-ARG1', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  George went with Kathy to the circus\n",
            "Predicted BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-MNR', 'I-ARGM-MNR', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Alice went with Deborah to the bank\n",
            "Predicted BIO tags:  ['B-ARG1', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Kathy went with Anna to the theatre\n",
            "Predicted BIO tags:  ['B-ARGM-MNR', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Frederick went with Jean to the castle\n",
            "Predicted BIO tags:  ['B-ARG1', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Joe went with Lauren to the hospital\n",
            "Predicted BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-MNR', 'I-ARGM-MNR', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Michelle went with Christine to the library\n",
            "Predicted BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-MNR', 'I-ARGM-MNR', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Lauren went with Ken to the shop\n",
            "Predicted BIO tags:  ['B-ARG1', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Don went with Marilyn to the auction\n",
            "Predicted BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-PRD', 'I-ARGM-PRD', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Sharon went with Julia to the DMV\n",
            "Predicted BIO tags:  ['B-ARG1', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Sarah went with Joan to the club\n",
            "Predicted BIO tags:  ['B-ARG1', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Jean went with Dorothy to the theatre\n",
            "Predicted BIO tags:  ['B-ARG1', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Emily went with Billy to the game\n",
            "Predicted BIO tags:  ['B-ARG1', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Paul went with Katherine to the Y\n",
            "Predicted BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-MNR', 'I-ARGM-MNR', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Frank went with Chris to the show\n",
            "Predicted BIO tags:  ['B-ARG1', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Sarah went with Steven to the field\n",
            "Predicted BIO tags:  ['B-ARG1', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Catherine went with Amy to the pub\n",
            "Predicted BIO tags:  ['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  Frances went with Edward to the restaurant\n",
            "Predicted BIO tags:  ['B-ARG1', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "Rate of failure:  38.0 Total number of example:  100\n"
          ]
        }
      ],
      "source": [
        "with open(path+f\"FirstNames_sents.json\", 'r') as f:\n",
        "        sentences = json.load(f)\n",
        "\n",
        "labels=sentences[\"labels\"]\n",
        "sentences=sentences['data']\n",
        "failure=eval_full_sent_BIOtags(sentences,labels,predictor,verbose=True)\n",
        "\n",
        "print(f\"Rate of failure: \",failure,\"Total number of example: \",len(sentences))\n",
        "\n",
        "append_to_results(results_path,{f\"FistNames\":failure})\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pronouns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " FAILED FOR Sentence:  We went with them to the Capitol\n",
            "Predicted BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-MNR', 'I-ARGM-MNR', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  We went with them to the war\n",
            "Predicted BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-MNR', 'I-ARGM-MNR', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "\n",
            " FAILED FOR Sentence:  She went with them to the movie\n",
            "Predicted BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-MNR', 'I-ARGM-MNR', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "True BIO tags:  ['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'B-ARG4', 'I-ARG4', 'I-ARG4']\n",
            "Rate of failure:  3.0 Total number of example:  100\n"
          ]
        }
      ],
      "source": [
        "with open(path+f\"Pronouns_sents.json\", 'r') as f:\n",
        "        sentences = json.load(f)\n",
        "\n",
        "labels=sentences[\"labels\"]\n",
        "sentences=sentences['data']\n",
        "failure=eval_full_sent_BIOtags(sentences,labels,predictor,verbose=True)\n",
        "\n",
        "print(f\"Rate of failure: \",failure,\"Total number of example: \",len(sentences))\n",
        "\n",
        "append_to_results(results_path,{f\"Pronouns\":failure})\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## AMBIGUITY/TAXONOMY (PP-ATTACHMENT AMBIGUITY)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PP-ATTACHMENT AMBIGUITY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentences=\"I went to the resturant by the Hutsin\", \"I went to the resturant by\"\n",
        "[\"I fixed the car with a red logo\",\"I fixed the car with a wretch\"]\n",
        "[\"I bought a computer with GPU\",\" I bought a computer wit bitcoins\"]\n",
        "\n",
        "for s in sentences:\n",
        "  print(s)\n",
        "  pred=predictor.predict(s)\n",
        "  desc=[x['description'] for x in pred['verbs']]\n",
        "  #print(verbs)\n",
        "  print(desc)\n",
        "  print(\"\\n\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'verbs': [{'verb': 'killed',\n",
              "   'description': '[ARG0: I] [V: killed] [ARG1: a rabbit] [ARG2: with a knife]',\n",
              "   'tags': ['B-ARG0',\n",
              "    'B-V',\n",
              "    'B-ARG1',\n",
              "    'I-ARG1',\n",
              "    'B-ARG2',\n",
              "    'I-ARG2',\n",
              "    'I-ARG2']}],\n",
              " 'words': ['I', 'killed', 'a', 'rabbit', 'with', 'a', 'knife']}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred=predictor_Bert.predict(\"I killed a rabbit with a knife\")\n",
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'verbs': [{'verb': 'eats',\n",
              "   'description': '[ARG0: Alice] [V: eats] [ARG1: a chicken] [ARGM-MNR: with a fork] .',\n",
              "   'tags': ['B-ARG0',\n",
              "    'B-V',\n",
              "    'B-ARG1',\n",
              "    'I-ARG1',\n",
              "    'B-ARGM-MNR',\n",
              "    'I-ARGM-MNR',\n",
              "    'I-ARGM-MNR',\n",
              "    'O']}],\n",
              " 'words': ['Alice', 'eats', 'a', 'chicken', 'with', 'a', 'fork', '.']}"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred=predictor_Bert.predict(\"Alice eats a chicken with a fork.\")\n",
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'verbs': [{'verb': 'eats', 'description': '[ARG0: Lukas] [V: eats] [ARG1: a chicken with a feather] .', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'O']}], 'words': ['Lukas', 'eats', 'a', 'chicken', 'with', 'a', 'feather', '.']}\n",
            "{'verbs': [{'verb': 'eats', 'description': '[ARG0: Lukas] [V: eats] [ARG1: a chicken] [ARGM-MNR: with a stick] .', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'B-ARGM-MNR', 'I-ARGM-MNR', 'I-ARGM-MNR', 'O']}], 'words': ['Lukas', 'eats', 'a', 'chicken', 'with', 'a', 'stick', '.']}\n"
          ]
        }
      ],
      "source": [
        "s=['Lukas eats a chicken with a feather.', 'Lukas eats a chicken with a stick.']\n",
        "for x in s:\n",
        "    pred=predictor_Bert.predict(x)\n",
        "    print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'verbs': [{'verb': 'eats', 'description': '[ARG0: Lukas] [V: eats] [ARG1: a chicken] [ARGM-MNR: with hands] .', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'B-ARGM-MNR', 'I-ARGM-MNR', 'O']}], 'words': ['Lukas', 'eats', 'a', 'chicken', 'with', 'hands', '.']}\n",
            "{'verbs': [{'verb': 'eats', 'description': '[ARG0: Lukas] [V: eats] [ARG1: a chicken with olives] .', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'O']}], 'words': ['Lukas', 'eats', 'a', 'chicken', 'with', 'olives', '.']}\n"
          ]
        }
      ],
      "source": [
        "s=['Lukas eats a chicken with hands.', 'Lukas eats a chicken with olives.']\n",
        "for x in s:\n",
        "    pred=predictor_Bert.predict(x)\n",
        "    print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'verbs': [{'verb': 'eats', 'description': '[ARG0: Lukas] [V: eats] [ARG1: a chicken] [ARG2: with tomatoes] .', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'B-ARG2', 'I-ARG2', 'O']}], 'words': ['Lukas', 'eats', 'a', 'chicken', 'with', 'tomatoes', '.']}\n",
            "{'verbs': [{'verb': 'eats', 'description': '[ARG0: Lukas] [V: eats] [ARG1: a chicken] [ARGM-MNR: with forks] .', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'B-ARGM-MNR', 'I-ARGM-MNR', 'O']}], 'words': ['Lukas', 'eats', 'a', 'chicken', 'with', 'forks', '.']}\n"
          ]
        }
      ],
      "source": [
        "s=['Lukas eats a chicken with tomatoes.', 'Lukas eats a chicken with forks.']\n",
        "for x in s:\n",
        "    pred=predictor_Bert.predict(x)\n",
        "    print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'verbs': [{'verb': 'drink', 'description': '[ARG0: I] [V: drink] [ARG1: whisky] [ARGM-MNR: with Ice]', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'B-ARGM-MNR', 'I-ARGM-MNR']}], 'words': ['I', 'drink', 'whisky', 'with', 'Ice']}\n",
            "{'verbs': [{'verb': 'drink', 'description': '[ARG0: I] [V: drink] [ARG1: wiskey] [ARGM-COM: with Jhon]', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'B-ARGM-COM', 'I-ARGM-COM']}], 'words': ['I', 'drink', 'wiskey', 'with', 'Jhon']}\n"
          ]
        }
      ],
      "source": [
        "s=['I drink whisky with Ice', 'I drink wiskey with Jhon']\n",
        "for x in s:\n",
        "    pred=predictor_Bert.predict(x)\n",
        "    print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'verbs': [{'verb': 'have', 'description': '[ARG0: I] [V: have] [ARG1: breakfast] [ARGM-MNR: with Coffee]', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'B-ARGM-MNR', 'I-ARGM-MNR']}], 'words': ['I', 'have', 'breakfast', 'with', 'Coffee']}\n",
            "{'verbs': [{'verb': 'have', 'description': '[ARG0: I] [V: have] [ARG1: breakfast] [ARGM-COM: with Sunny]', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'B-ARGM-COM', 'I-ARGM-COM']}], 'words': ['I', 'have', 'breakfast', 'with', 'Sunny']}\n"
          ]
        }
      ],
      "source": [
        "s=['I have breakfast with Coffee', 'I have breakfast with Sunny']\n",
        "for x in s:\n",
        "    pred=predictor_Bert.predict(x)\n",
        "    print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'verbs': [{'verb': 'come', 'description': '[ARG1: I] [V: come] [ARGM-MNR: by bike]', 'tags': ['B-ARG1', 'B-V', 'B-ARGM-MNR', 'I-ARGM-MNR']}], 'words': ['I', 'come', 'by', 'bike']}\n",
            "{'verbs': [{'verb': 'come', 'description': '[ARG1: I] [V: come] [ARGM-TMP: by noon]', 'tags': ['B-ARG1', 'B-V', 'B-ARGM-TMP', 'I-ARGM-TMP']}], 'words': ['I', 'come', 'by', 'noon']}\n"
          ]
        }
      ],
      "source": [
        "s=['I come by bike', 'I come by noon']\n",
        "for x in s:\n",
        "    pred=predictor_Bert.predict(x)\n",
        "    print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'verbs': [{'verb': 'saw', 'description': '[ARG0: Lukas] [V: saw] [ARG1: a man with a knife]', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1']}], 'words': ['Lukas', 'saw', 'a', 'man', 'with', 'a', 'knife']}\n",
            "{'verbs': [{'verb': 'saw', 'description': '[ARG0: Lukas] [V: saw] [ARG1: a man] [ARGM-MNR: with binoculars]', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'B-ARGM-MNR', 'I-ARGM-MNR']}], 'words': ['Lukas', 'saw', 'a', 'man', 'with', 'binoculars']}\n"
          ]
        }
      ],
      "source": [
        "s=['Lukas saw a man with a knife', 'Lukas saw a man with binoculars']\n",
        "for x in s:\n",
        "    pred=predictor_Bert.predict(x)\n",
        "    print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'verbs': [{'verb': 'having', 'description': '[ARG0: Lukas] [V: having] [ARG1: a beer] [ARGM-COM: with a friend] .', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'B-ARGM-COM', 'I-ARGM-COM', 'I-ARGM-COM', 'O']}], 'words': ['Lukas', 'having', 'a', 'beer', 'with', 'a', 'friend', '.']}\n",
            "{'verbs': [{'verb': 'having', 'description': '[ARG0: Lukas] [V: having] [ARG1: a beer] [ARG2: with a lemon] .', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'B-ARG2', 'I-ARG2', 'I-ARG2', 'O']}], 'words': ['Lukas', 'having', 'a', 'beer', 'with', 'a', 'lemon', '.']}\n"
          ]
        }
      ],
      "source": [
        "s=[\"Lukas having a beer with a friend.\",\"Lukas having a beer with a lemon.\"]\n",
        "for x in s:\n",
        "    pred=predictor_Bert.predict(x)\n",
        "    print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'verbs': [{'verb': 'helps', 'description': '[ARG0: Lukas] [V: helps] [ARG2: a man with a disability] .', 'tags': ['B-ARG0', 'B-V', 'B-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'O']}], 'words': ['Lukas', 'helps', 'a', 'man', 'with', 'a', 'disability', '.']}\n",
            "{'verbs': [{'verb': 'helps', 'description': '[ARG0: Lukas] [V: helps] [ARG2: a man] [ARG1: with a task] .', 'tags': ['B-ARG0', 'B-V', 'B-ARG2', 'I-ARG2', 'B-ARG1', 'I-ARG1', 'I-ARG1', 'O']}], 'words': ['Lukas', 'helps', 'a', 'man', 'with', 'a', 'task', '.']}\n"
          ]
        }
      ],
      "source": [
        "s=[\"Lukas helps a man with a disability.\",\"Lukas helps a man with a task.\"]\n",
        "for x in s:\n",
        "    pred=predictor_Bert.predict(x)\n",
        "    print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SPAN IDENTIFICATION"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LONG NER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def eval_NER(sentences,predictor):\n",
        "    fails=0\n",
        "    golden=['B-ARG0', 'I-ARG0', 'I-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'I-ARG1', 'B-ARGM-LOC', 'I-ARGM-LOC']\n",
        "    for s in sentences:\n",
        "        pred=predictor.predict(s)\n",
        "        success=check_NER_tags(pred,golden)\n",
        "        if not success:\n",
        "            fails+=1\n",
        "    return fails/len(sentences)*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failure rate: 67.0. Total number of tests: 100\n"
          ]
        }
      ],
      "source": [
        "\n",
        "with open(path+\"NER_sentences.json\",\"r\") as f:\n",
        "    di=json.load(f)\n",
        "\n",
        "golden=list(di.keys())[0]\n",
        "sentences=di[golden]\n",
        "golden=['B-ARG0', 'I-ARG0', 'I-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'I-ARG1', 'B-ARGM-LOC', 'I-ARGM-LOC']\n",
        "rate=eval_NER(sentences,predictor)\n",
        "print(f\"Failure rate: {rate}. Total number of tests: {len(sentences)}\")\n",
        "append_to_results(results_path,{f\"NER_sents\":rate})\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LONG SPAN ADJECTIVES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "djlQjIyAQIjV"
      },
      "source": [
        "## ROBUSTNESS"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Typos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rate of failure with 1 typos per sentence:  16.0\n",
            "Rate of failure with 2 typos per sentence:  38.0\n",
            "Rate of failure with 3 typos per sentence:  47.0\n",
            "Rate of failure with 4 typos per sentence:  52.0\n"
          ]
        }
      ],
      "source": [
        "for i in range(1,5):#becuase we have 4 files like that\n",
        "\n",
        "    with open(path+f\"sents_{i}_typos.json\", 'r') as f:\n",
        "        sentences = json.load(f)\n",
        "\n",
        "    labels=sentences.pop(\"labels\")\n",
        "    sentences=list(sentences.values())\n",
        "    rate_typos_n=eval_full_sent_BIOtags(sentences,labels,predictor,verbose=False)\n",
        "\n",
        "    print(f\"Rate of failure with {i} typos per sentence: \",rate_typos_n)\n",
        "\n",
        "    append_to_results(results_path,{f\"sents_{i}_typos\":rate_typos_n})\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PARAPHRASING"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hGIRP7dVbw_W"
      },
      "source": [
        "### passive and actrive trasnformarion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "different arguments\n",
            "different arguments\n",
            "different arguments\n",
            "different arguments\n",
            "different arguments\n",
            "Rate of failure with for INV activepassive  21.73913043478261\n"
          ]
        }
      ],
      "source": [
        "with open(path+\"activepassive_sentences.json\", 'r') as f:\n",
        "    sentences = json.load(f)\n",
        "\n",
        "sentences=list(sentences.items())\n",
        "\n",
        "rate=eval_predictor_INV(sentences,predictor,\"evaluate_INV_sameArgs\")\n",
        "\n",
        "print(f\"Rate of failure with for INV activepassive \",rate)\n",
        "\n",
        "append_to_results(results_path,{f\"activepassive_sents\":rate})\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zfvIn-8biqxc"
      },
      "source": [
        "### Questions phrasing\n",
        "Idea for testing is to take all the arguments from from the verb that is the same(not the auxialiry).\n",
        " All the arguments should be the same except for the verb."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "different arguments\n",
            "Rate of failure with for INV in question rephrasing task  7.142857142857142\n"
          ]
        }
      ],
      "source": [
        "with open(path+\"question_rephrase.json\", 'r') as f:\n",
        "    sentences = json.load(f)\n",
        "\n",
        "sentences=list(sentences.items())\n",
        "\n",
        "rate=eval_predictor_INV(sentences,predictor,\"evaluate_INV_sameArgs\")\n",
        "\n",
        "print(f\"Rate of failure with for INV in question rephrasing task \",rate)\n",
        "\n",
        "append_to_results(results_path,{f\"question_rephrase\":rate})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\npred1=predictor_Bert.predict(\"It annoys me the results of the election\")\\npred1\\n\\n\\npred=predictor_Bert.predict(\"It Is great the results of the election\")\\npred\\n\\npred=predictor_Bert.predict(\"He was the one that did not want to go to the party\")\\nfor v in pred[\\'verbs\\']:\\n  print(v[\\'description\\'])\\n  \\n\\npred=predictor_Bert.predict(\"she is the sister that likes milk\")\\nfor v in pred[\\'verbs\\']:\\n  print(v[\\'description\\'])\\n  \\n\\nrelative_pronouns = {\\n    \"who\": \"The person who stole my bike was caught by the police.\",\\n    \"whom\": \"The woman whom I saw at the store was carrying a lot of groceries.\",\\n    \"which\": \"The car which I rented for my vacation was very comfortable.\",\\n    \"whose\": \"The man whose wallet was lost reported the incident to the authorities.\",\\n    \"where\": \"The park where we had our picnic was very peaceful.\",\\n    \"when\": \"The time when we first met is a very special memory for me.\",\\n    \"that\": \"The book that I\\'m reading right now is very suspenseful.\",\\n    \"whoever\": \"Whoever finishes first gets a prize.\",\\n    \"whichever\": \"You can choose whichever movie you want to see.\",\\n}\\nfor x in relative_pronouns:\\n  print(x)\\n  pred=predictor_Bert.predict(relative_pronouns[x])\\n  for v in pred[\\'verbs\\']:\\n    print(v[\\'description\\'])\\n  \\npred=predictor_Bert.predict(\"The partner of the lady, who is very old, has exacly my t-shirt\")\\npred\\npred[\\'verbs\\'][0][\\'description\\']\\n\\npred=predictor_Bert.predict(\"The partner of the lady who is very old, has exacly my t-shirt\")\\npred\\npred[\\'verbs\\'][0][\\'description\\']\\n\\npred=predictor_Bert.predict(\"The partner of the lady who is very old has exacly my t-shirt\")\\npred\\npred[\\'verbs\\'][0][\\'description\\']\\npred=predictor_Bert.predict(\"The cars in the shop which is expensive, are exacly what i dream\")\\npred\\npred[\\'verbs\\'][0][\\'description\\']\\n\\nOk so the idea is the coreference u dont need here becuase SRL is sentence based very much and for every predicate\\nyou have a sentence. So the coreference is not needed. But sometimes you have that in the same sentence.\\n'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "pred1=predictor_Bert.predict(\"It annoys me the results of the election\")\n",
        "pred1\n",
        "\n",
        "\n",
        "pred=predictor_Bert.predict(\"It Is great the results of the election\")\n",
        "pred\n",
        "\n",
        "pred=predictor_Bert.predict(\"He was the one that did not want to go to the party\")\n",
        "for v in pred['verbs']:\n",
        "  print(v['description'])\n",
        "  \n",
        "\n",
        "pred=predictor_Bert.predict(\"she is the sister that likes milk\")\n",
        "for v in pred['verbs']:\n",
        "  print(v['description'])\n",
        "  \n",
        "\n",
        "relative_pronouns = {\n",
        "    \"who\": \"The person who stole my bike was caught by the police.\",\n",
        "    \"whom\": \"The woman whom I saw at the store was carrying a lot of groceries.\",\n",
        "    \"which\": \"The car which I rented for my vacation was very comfortable.\",\n",
        "    \"whose\": \"The man whose wallet was lost reported the incident to the authorities.\",\n",
        "    \"where\": \"The park where we had our picnic was very peaceful.\",\n",
        "    \"when\": \"The time when we first met is a very special memory for me.\",\n",
        "    \"that\": \"The book that I'm reading right now is very suspenseful.\",\n",
        "    \"whoever\": \"Whoever finishes first gets a prize.\",\n",
        "    \"whichever\": \"You can choose whichever movie you want to see.\",\n",
        "}\n",
        "for x in relative_pronouns:\n",
        "  print(x)\n",
        "  pred=predictor_Bert.predict(relative_pronouns[x])\n",
        "  for v in pred['verbs']:\n",
        "    print(v['description'])\n",
        "  \n",
        "pred=predictor_Bert.predict(\"The partner of the lady, who is very old, has exacly my t-shirt\")\n",
        "pred\n",
        "pred['verbs'][0]['description']\n",
        "\n",
        "pred=predictor_Bert.predict(\"The partner of the lady who is very old, has exacly my t-shirt\")\n",
        "pred\n",
        "pred['verbs'][0]['description']\n",
        "\n",
        "pred=predictor_Bert.predict(\"The partner of the lady who is very old has exacly my t-shirt\")\n",
        "pred\n",
        "pred['verbs'][0]['description']\n",
        "pred=predictor_Bert.predict(\"The cars in the shop which is expensive, are exacly what i dream\")\n",
        "pred\n",
        "pred['verbs'][0]['description']\n",
        "\n",
        "Ok so the idea is the coreference u dont need here becuase SRL is sentence based very much and for every predicate\n",
        "you have a sentence. So the coreference is not needed. But sometimes you have that in the same sentence.\n",
        "\"\"\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "88Z28UZUr6NW"
      },
      "source": [
        "#### PP -ambiguity\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__UUhlKKi0II",
        "outputId": "df279aeb-590e-497c-9510-393de9163699"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I went to the resturant by the Hutsin\n",
            "['[ARG0: I] [V: went] [ARG4: to the resturant by the Hutsin]']\n",
            "\n",
            "\n",
            "\n",
            "I went to the resturant by bike\n",
            "['[ARG0: I] [V: went] [ARG4: to the resturant] [ARGM-MNR: by bike]']\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqHUwgoCr7OA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7i47oLC8qoSV"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "18hqUeT2Yije"
      },
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AsWFgLOtBAOh"
      },
      "source": [
        "# The cimitery of tests... [DONT RUN]\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qywAgrXmqR8S"
      },
      "source": [
        "### INCISI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIVdwIEqTDI",
        "outputId": "d2fc01e9-3d77-4c96-ef0c-a1aa102d3f19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This, friend, is epic \n",
            "['[ARG1: This ,] [ARGM-DIS: friend] , [V: is] [ARG2: epic]']\n",
            "\n",
            "\n",
            "\n",
            "This friend is epic\n",
            "['[ARG1: This friend] [V: is] [ARG2: epic]']\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sentences=[\"This, friend, is epic \",\"This friend is epic\"]\n",
        "for s in sentences:\n",
        "  print(s)\n",
        "  pred=predictor_Bert.predict(s)\n",
        "  desc=[x['description'] for x in pred['verbs']]\n",
        "  #print(verbs)\n",
        "  print(desc)\n",
        "  print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFQzrpEHqajZ"
      },
      "outputs": [],
      "source": [
        "(I might stay, tonight, with you)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1qa_YDiogvoa"
      },
      "source": [
        "### DIfferent frames for labels recognition\n",
        "With mutiple verbs, argoument confusion "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JoQIAH4WY2Kl"
      },
      "source": [
        "### Saxon genitive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqJO-kASY35h"
      },
      "outputs": [],
      "source": [
        "paired_sentences = [    [\"The president's decision to withdraw troops from the region caused controversy among military leaders.\",      \"The decision of the president to withdraw troops from the region caused controversy among military leaders.\"],\n",
        "    [\"The CEO's success in turning around the struggling company was due in large part to her innovative marketing strategies.\",      \"The success of the CEO in turning around the struggling company was due in large part to her innovative marketing strategies.\"],\n",
        "    [\"The director's vision for the film was not fully realized due to budget constraints and scheduling conflicts.\",      \"The vision of the director for the film was not fully realized due to budget constraints and scheduling conflicts.\"],\n",
        "    [\"The professor's lecture on the history of ancient Rome was attended by a packed auditorium of eager students.\",      \"The lecture on the history of ancient Rome of the professor was attended by a packed auditorium of eager students.\"],\n",
        "    [\"The artist's latest work, a sculpture made entirely of recycled materials, was featured in a prominent gallery exhibition.\",      \"The latest work of the artist, a sculpture made entirely of recycled materials, was featured in a prominent gallery exhibition.\"],\n",
        "    [\"The athlete's rigorous training regimen and strict diet led to her record-breaking performance at the championship.\",      \"The rigorous training regimen and strict diet of the athlete led to her record-breaking performance at the championship.\"],\n",
        "    [\"The author's use of symbolism and metaphor in her novel added depth and complexity to the story.\",      \"The use of symbolism and metaphor in her novel of the author added depth and complexity to the story.\"]\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xA-tIuKeeFwl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3HiN4_geN9E"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bZmRzaqwSkTM"
      },
      "source": [
        "### Intransitive verbs"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Intransitive verbs can be tricky:\n",
        "So there Unaccusative and Uneragtive are intrasntivie verbs. The difference is that unergative the subject is considered an againt, initating the action. whereas unaccusative the subject is considered the patient of the action.\n",
        "Naomi worked [argent]\n",
        "Naomi fell  [theme/patinet]\n",
        "\n",
        "an MFT test can just intransitive verbs being used as transitive verbs.\n",
        "\n",
        "and a directionality test can be used to see if the model is able to recognize the difference between unergative and unaccusative verbs. \n",
        "like the butter melted - the butter smells\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U47CiSLSsia",
        "outputId": "eba4faa3-5a89-48aa-a482-9a951d02eb1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sun rises in the east.\n",
            "['[ARG1: The sun] [V: rises] [ARGM-LOC: in the east] .']\n",
            "\n",
            "\n",
            "\n",
            "He slept for 10 hours.\n",
            "['[ARG0: He] [V: slept] [ARGM-TMP: for 10 hours] .']\n",
            "\n",
            "\n",
            "\n",
            "They danced all night.\n",
            "['[ARG0: They] [V: danced] [ARGM-TMP: all night] .']\n",
            "\n",
            "\n",
            "\n",
            "The flowers bloomed in the spring.\n",
            "['[ARG0: The flowers] [V: bloomed] [ARGM-TMP: in the spring] .']\n",
            "\n",
            "\n",
            "\n",
            "The baby cried all night.\n",
            "['[ARG0: The baby] [V: cried] [ARGM-TMP: all night] .']\n",
            "\n",
            "\n",
            "\n",
            "The cat meowed loudly.\n",
            "['[ARG0: The cat] [V: meowed] [ARGM-MNR: loudly] .']\n",
            "\n",
            "\n",
            "\n",
            "The car stopped suddenly.\n",
            "['[ARG1: The car] [V: stopped] [ARGM-MNR: suddenly] .']\n",
            "\n",
            "\n",
            "\n",
            "She ran around the park.\n",
            "['[ARG0: She] [V: ran] [ARGM-DIR: around the park] .']\n",
            "\n",
            "\n",
            "\n",
            "The plane took off at 9 am.\n",
            "['[ARG1: The plane] [V: took] off [ARGM-TMP: at 9 am] .']\n",
            "\n",
            "\n",
            "\n",
            "The wind blew fiercely.\n",
            "['[ARG1: The wind] [V: blew] [ARGM-MNR: fiercely] .']\n",
            "\n",
            "\n",
            "\n",
            "The tree swayed in the wind.\n",
            "['[ARG1: The tree] [V: swayed] [ARGM-LOC: in the wind] .']\n",
            "\n",
            "\n",
            "\n",
            "The river flows downstream.\n",
            "['[ARG1: The river] [V: flows] [ARGM-DIR: downstream] .']\n",
            "\n",
            "\n",
            "\n",
            "The coffee brewed in the pot.\n",
            "['[ARG1: The coffee] [V: brewed] [ARGM-LOC: in the pot] .']\n",
            "\n",
            "\n",
            "\n",
            "The music played softly in the background.\n",
            "['[ARG1: The music] [V: played] [ARGM-MNR: softly] [ARGM-LOC: in the background] .']\n",
            "\n",
            "\n",
            "\n",
            "The bird chirped early in the morning.\n",
            "['[ARG0: The bird] [V: chirped] [ARGM-TMP: early in the morning] .']\n",
            "\n",
            "\n",
            "\n",
            "The children laughed and played.\n",
            "['[ARG0: The children] [V: laughed] and played .', '[ARG0: The children] laughed and [V: played] .']\n",
            "\n",
            "\n",
            "\n",
            "The fire crackled in the fireplace.\n",
            "['[ARG0: The fire] [V: crackled] [ARGM-LOC: in the fireplace] .']\n",
            "\n",
            "\n",
            "\n",
            "The leaves fell from the trees.\n",
            "['[ARG1: The leaves] [V: fell] [ARG3: from the trees] .']\n",
            "\n",
            "\n",
            "\n",
            "The boat sailed across the ocean.\n",
            "['[ARG0: The boat] [V: sailed] [ARGM-DIR: across the ocean] .']\n",
            "\n",
            "\n",
            "\n",
            "The train arrived at the station on time.\n",
            "['[ARG1: The train] [V: arrived] [ARG4: at the station] [ARGM-TMP: on time] .']\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for s in sentences:\n",
        "  print(s)\n",
        "  pred=predictor.predict(s)\n",
        "  desc=[x['description'] for x in pred['verbs']]\n",
        "  #print(verbs)\n",
        "  print(desc)\n",
        "  print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crDSij6dS3XA"
      },
      "outputs": [],
      "source": [
        "sentences = ['The snow fell gently from the sky.',\n",
        "             'She laughed uncontrollably at the joke.',\n",
        "             'The sun set over the horizon.',\n",
        "             'The children played happily in the park.',\n",
        "             'The fire burned brightly in the fireplace.',\n",
        "             'The wind howled outside the window.',\n",
        "             'The cake baked for an hour.',\n",
        "             'The door opened slowly.',\n",
        "             'The crowd cheered loudly at the concert.',\n",
        "             'The athlete ran around the track.',\n",
        "             'The tree grew tall and strong.',\n",
        "             'The river flowed peacefully.',\n",
        "             'The bird flew gracefully through the air.',\n",
        "             'The fish swam quickly in the water.',\n",
        "             'The dog barked loudly at the mailman.',\n",
        "             'The car drove smoothly down the road.',\n",
        "             'The plane flew high above the clouds.',\n",
        "             'The moon shone brightly in the sky.',\n",
        "             'The stars twinkled in the night sky.',\n",
        "             'The flowers swayed in the breeze.']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W15h4WVZJFj",
        "outputId": "4af66d47-d0cc-4f15-9b9f-0afd4dbded95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The snow fell gently from the sky.\n",
            "['[ARG1: The snow] [V: fell] [ARGM-MNR: gently] [ARG3: from the sky] .']\n",
            "\n",
            "\n",
            "\n",
            "She laughed uncontrollably at the joke.\n",
            "['[ARG0: She] [V: laughed] [ARGM-MNR: uncontrollably] [ARG2: at the joke] .']\n",
            "\n",
            "\n",
            "\n",
            "The sun set over the horizon.\n",
            "['[ARG1: The sun] [V: set] [ARG2: over the horizon] .']\n",
            "\n",
            "\n",
            "\n",
            "The children played happily in the park.\n",
            "['[ARG0: The children] [V: played] [ARGM-MNR: happily] [ARGM-LOC: in the park] .']\n",
            "\n",
            "\n",
            "\n",
            "The fire burned brightly in the fireplace.\n",
            "['[ARG1: The fire] [V: burned] [ARGM-MNR: brightly] [ARGM-LOC: in the fireplace] .']\n",
            "\n",
            "\n",
            "\n",
            "The wind howled outside the window.\n",
            "['[ARG0: The wind] [V: howled] [ARGM-LOC: outside the window] .']\n",
            "\n",
            "\n",
            "\n",
            "The cake baked for an hour.\n",
            "['[ARG1: The cake] [V: baked] [ARGM-TMP: for an hour] .']\n",
            "\n",
            "\n",
            "\n",
            "The door opened slowly.\n",
            "['[ARG1: The door] [V: opened] [ARGM-MNR: slowly] .']\n",
            "\n",
            "\n",
            "\n",
            "The crowd cheered loudly at the concert.\n",
            "['[ARG0: The crowd] [V: cheered] [ARGM-MNR: loudly] [ARG1: at the concert] .']\n",
            "\n",
            "\n",
            "\n",
            "The athlete ran around the track.\n",
            "['[ARG0: The athlete] [V: ran] [ARGM-DIR: around the track] .']\n",
            "\n",
            "\n",
            "\n",
            "The tree grew tall and strong.\n",
            "['[ARG1: The tree] [V: grew] [ARGM-PRD: tall and strong] .']\n",
            "\n",
            "\n",
            "\n",
            "The river flowed peacefully.\n",
            "['[ARG1: The river] [V: flowed] [ARGM-MNR: peacefully] .']\n",
            "\n",
            "\n",
            "\n",
            "The bird flew gracefully through the air.\n",
            "['[ARG0: The bird] [V: flew] [ARGM-MNR: gracefully] [ARGM-DIR: through the air] .']\n",
            "\n",
            "\n",
            "\n",
            "The fish swam quickly in the water.\n",
            "[]\n",
            "\n",
            "\n",
            "\n",
            "The dog barked loudly at the mailman.\n",
            "['[ARG0: The dog] [V: barked] [ARGM-MNR: loudly] [ARG2: at the mailman] .']\n",
            "\n",
            "\n",
            "\n",
            "The car drove smoothly down the road.\n",
            "['[ARG0: The car] [V: drove] [ARGM-MNR: smoothly] [ARG1: down the road] .']\n",
            "\n",
            "\n",
            "\n",
            "The plane flew high above the clouds.\n",
            "['[ARG1: The plane] [V: flew] [ARGM-LOC: high above the clouds] .']\n",
            "\n",
            "\n",
            "\n",
            "The moon shone brightly in the sky.\n",
            "['[ARG1: The moon] [V: shone] [ARGM-MNR: brightly] [ARGM-LOC: in the sky] .']\n",
            "\n",
            "\n",
            "\n",
            "The stars twinkled in the night sky.\n",
            "['[ARG1: The stars] [V: twinkled] [ARGM-LOC: in the night sky] .']\n",
            "\n",
            "\n",
            "\n",
            "The flowers swayed in the breeze.\n",
            "['[ARG1: The flowers] [V: swayed] [ARGM-LOC: in the breeze] .']\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for s in sentences:\n",
        "  print(s)\n",
        "  pred=predictor.predict(s)\n",
        "  desc=[x['description'] for x in pred['verbs']]\n",
        "  #print(verbs)\n",
        "  print(desc)\n",
        "  print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNLh24X7Z5zo",
        "outputId": "5e4fee14-f665-4f11-9c04-f26c35025ffc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'verbs': [{'verb': 'keep',\n",
              "   'description': '[ARG0: Many people] [V: keep] [ARG1: falling for this CON - GAME that lower taxes on the rich benefits everyone] .',\n",
              "   'tags': ['B-ARG0',\n",
              "    'I-ARG0',\n",
              "    'B-V',\n",
              "    'B-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'O']},\n",
              "  {'verb': 'falling',\n",
              "   'description': '[ARG1: Many people] keep [V: falling] [ARGM-PRP: for this CON - GAME that lower taxes on the rich benefits everyone] .',\n",
              "   'tags': ['B-ARG1',\n",
              "    'I-ARG1',\n",
              "    'O',\n",
              "    'B-V',\n",
              "    'B-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'I-ARGM-PRP',\n",
              "    'O']}],\n",
              " 'words': ['Many',\n",
              "  'people',\n",
              "  'keep',\n",
              "  'falling',\n",
              "  'for',\n",
              "  'this',\n",
              "  'CON',\n",
              "  '-',\n",
              "  'GAME',\n",
              "  'that',\n",
              "  'lower',\n",
              "  'taxes',\n",
              "  'on',\n",
              "  'the',\n",
              "  'rich',\n",
              "  'benefits',\n",
              "  'everyone',\n",
              "  '.']}"
            ]
          },
          "execution_count": 161,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sent=\"Many people keep falling for this CON - GAME that lower taxes on the rich benefits everyone . \"\n",
        "predictor.predict(sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpYziEq6aAhf",
        "outputId": "bf89e4fd-b324-43fd-9fe2-22d18b2ec2e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'verbs': [{'verb': 'walked',\n",
              "   'description': '[ARG0: He] [V: walked] [ARG1: the dog] [ARGM-GOL: to the park and back] .',\n",
              "   'tags': ['B-ARG0',\n",
              "    'B-V',\n",
              "    'B-ARG1',\n",
              "    'I-ARG1',\n",
              "    'B-ARGM-GOL',\n",
              "    'I-ARGM-GOL',\n",
              "    'I-ARGM-GOL',\n",
              "    'I-ARGM-GOL',\n",
              "    'I-ARGM-GOL',\n",
              "    'O']}],\n",
              " 'words': ['He',\n",
              "  'walked',\n",
              "  'the',\n",
              "  'dog',\n",
              "  'to',\n",
              "  'the',\n",
              "  'park',\n",
              "  'and',\n",
              "  'back',\n",
              "  '.']}"
            ]
          },
          "execution_count": 163,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.predict(\"He walked the dog to the park and back.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPbWPYbidmKY",
        "outputId": "426766eb-8c35-4be3-e22f-afe03b575d44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'verbs': [{'verb': 'walked',\n",
              "   'description': '[ARG0: He] [V: walked] [ARGM-COM: with the dog] [ARGM-GOL: to the park and back] .',\n",
              "   'tags': ['B-ARG0',\n",
              "    'B-V',\n",
              "    'B-ARGM-COM',\n",
              "    'I-ARGM-COM',\n",
              "    'I-ARGM-COM',\n",
              "    'B-ARGM-GOL',\n",
              "    'I-ARGM-GOL',\n",
              "    'I-ARGM-GOL',\n",
              "    'I-ARGM-GOL',\n",
              "    'I-ARGM-GOL',\n",
              "    'O']}],\n",
              " 'words': ['He',\n",
              "  'walked',\n",
              "  'with',\n",
              "  'the',\n",
              "  'dog',\n",
              "  'to',\n",
              "  'the',\n",
              "  'park',\n",
              "  'and',\n",
              "  'back',\n",
              "  '.']}"
            ]
          },
          "execution_count": 164,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.predict(\"He walked with the dog to the park and back.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyRX4rLYdzje",
        "outputId": "65eaa0f1-1bca-4953-e0f5-2ae227c50313"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'verbs': [{'verb': 'see',\n",
              "   'description': '[ARG0: I] [V: see] [ARG1: a man with a telescope under his arm]',\n",
              "   'tags': ['B-ARG0',\n",
              "    'B-V',\n",
              "    'B-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1',\n",
              "    'I-ARG1']}],\n",
              " 'words': ['I',\n",
              "  'see',\n",
              "  'a',\n",
              "  'man',\n",
              "  'with',\n",
              "  'a',\n",
              "  'telescope',\n",
              "  'under',\n",
              "  'his',\n",
              "  'arm']}"
            ]
          },
          "execution_count": 182,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.predict(\"I see a man with a telescope under his arm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9NCwD39fjDK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKENZLQKew3c",
        "outputId": "1e0d7a08-8386-4948-a908-01544f0742bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'verbs': [{'verb': 'took',\n",
              "   'description': '[ARG0: The plane] [V: took] [ARG1: a large turn]',\n",
              "   'tags': ['B-ARG0', 'I-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'I-ARG1']}],\n",
              " 'words': ['The', 'plane', 'took', 'a', 'large', 'turn']}"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.predict(\"The plane took a large turn\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parenthetical Elements "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM6/gtRwphs5tZvfVtQ94Aw",
      "collapsed_sections": [
        "GIkns01FKdQd",
        "McQzhKS4LCVk",
        "dY-h4bawK2Ky",
        "2ybvS9k6Bsin",
        "XbQEiiaFLHtT",
        "xura9sS5eOrc",
        "djlQjIyAQIjV",
        "vFvgduTVSxBn",
        "XzSt0hAmQcYJ",
        "x2IbgB-XRuWQ",
        "qywAgrXmqR8S",
        "LzgT37FWxTPY",
        "JoQIAH4WY2Kl",
        "bZmRzaqwSkTM"
      ],
      "include_colab_link": true,
      "mount_file_id": "1j1qfHJIwReXyO57Aq4uu12y1pKIrYqHv",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "nlptasks",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
